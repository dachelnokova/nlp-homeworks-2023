{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd89794e-2da5-4b06-a829-03389dae9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import razdel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a60b03-e1e8-45ea-9595-c6c59dfb70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df1e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, stratify=data.toxic, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21d292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217eeaa8",
   "metadata": {},
   "source": [
    "### Векторизация с дефолтной токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f01f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "X = vectorizer.fit_transform(train.comment) \n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2668da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6f6f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc133847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db89c16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2943f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b803474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.91      0.85       959\n",
      "         1.0       0.75      0.55      0.64       483\n",
      "\n",
      "    accuracy                           0.79      1442\n",
      "   macro avg       0.78      0.73      0.74      1442\n",
      "weighted avg       0.78      0.79      0.78      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1b869-af4a-42c5-9e4e-ffa1bee2499f",
   "metadata": {},
   "source": [
    "### Векторизация с токенизацией razdel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d67c7e-d5c6-425a-b54f-5de670fe6774",
   "metadata": {},
   "source": [
    "Вариант 1: применяем razdel_tokenizer напрямую в качестве аргумента в TfidfVectorizer.\n",
    "Токенизация происходит внутри TfidfVectorizer на этапе преобразования текста в векторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21224f5-0d3d-4e5d-9394-cb1758ceb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb026ff-f124-4ed1-8070-ed26b2e60164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    tokens = list(razdel_tokenize(text))\n",
    "    return ' '.join([token.text.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df911f2e-625b-416a-a8a9-939ff36175b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariachelnokova/myenv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=razdel_tokenizer, min_df=10, max_df=0.3)\n",
    "X = vectorizer.fit_transform(train.comment) \n",
    "X_test = vectorizer.transform(test.comment) \n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57cc2b40-5c5a-45e5-b50f-182d25b99bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.50      0.62       959\n",
      "         1.0       0.44      0.78      0.56       483\n",
      "\n",
      "    accuracy                           0.59      1442\n",
      "   macro avg       0.63      0.64      0.59      1442\n",
      "weighted avg       0.69      0.59      0.60      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93dfd55-9094-4611-ac07-c45152377b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e61fec-f127-4469-9a83-6b774851bb04",
   "metadata": {},
   "source": [
    "Вариант 2. Создаем новые столбцы \"tokens\" в тренировочном и тестовом наборах данных, содержащие кастомный токенизированный текст.\n",
    "Преобразует уже токенизированный с razdel текст из столбцов tokens в векторы с помощью TfidfVectorizer.\n",
    "При этом векторайзер видимо сам дополнительно токенизирует уже токенизированный текст своими механизмами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64a605f-a12c-4750-8796-35dffa5b104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация с razdel (создание новых столбцов в обучающей и тестовой выборках, содержащих токенизированные с razdel тексты)\n",
    "train['tokens'] = train['comment'].apply(razdel_tokenizer)\n",
    "test['tokens'] = test['comment'].apply(razdel_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66059fea-7c8a-4bcb-8dc5-05d35ca500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "X = vectorizer.fit_transform(train['tokens']) \n",
    "X_test = vectorizer.transform(test['tokens'])\n",
    "y = train['toxic'].values\n",
    "y_test = test['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ef5fe1-d89e-449e-9225-c23ee3da11e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.89      0.85       959\n",
      "         1.0       0.74      0.61      0.67       483\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.78      0.75      0.76      1442\n",
      "weighted avg       0.79      0.80      0.79      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629975d0-d45d-40ff-81df-35add62b1cd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Оценка\n",
    "Если задавать свой токенизатор на этапе обучения векторизатора как параметр, то качество модели сильно ухудшается.\n",
    "Если токенизировать текст своим токенизатором перед подачей векторизатору и при этом явно не задавать параметр \"tokenizer\", то результат получается другой: модель справилась лучше, чем при первом варианте кастомной токенизации, и примерно также, как с дефолтной токенизацией, по всем основным метриками для обоих классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec096608-397d-46bb-aa88-978d3b8537a3",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer + MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecb1b455-a4c3-4d56-8ae6-4a571f63fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.2-cp311-cp311-macosx_10_9_x86_64.whl (24.1 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/dariachelnokova/myenv/lib/python3.11/site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/dariachelnokova/myenv/lib/python3.11/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/dariachelnokova/myenv/lib/python3.11/site-packages (from gensim) (6.4.0)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a5774e0-39bd-4bff-aa2a-7b7ddf97984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe5d0ae-eec2-4b4c-87cc-cf8aaccc4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_tokenizer(text):\n",
    "    return list(tokenize(text, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariachelnokova/myenv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=gensim_tokenizer, min_df=4, max_df=0.8, max_features=5000, ngram_range=(1,2))\n",
    "X = count_vectorizer.fit_transform(train.comment)\n",
    "X_test = count_vectorizer.transform(test.comment) \n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b971cb-fdc3-45d9-90fa-1e2b276ced27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.87       937\n",
      "         1.0       0.76      0.77      0.76       505\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.82      0.82      0.82      1442\n",
      "weighted avg       0.83      0.83      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1, fit_prior=False)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e18b3239-2757-4a8f-a838-0f7e057f646e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Вероятности принадлежности к классу 1 (токсичные)\n",
    "probs = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Создаем DataFrame с предсказаниями и вероятностями\n",
    "predictions_df = pd.DataFrame({\n",
    "    'text': test['comment'],  # Тексты из тестовой выборки\n",
    "    'toxicity_prediction': preds,  # Предсказания\n",
    "    'toxicity_probability': probs  # Вероятности\n",
    "})\n",
    "\n",
    "# Находим 10 самых токсичных текстов\n",
    "top_10_toxic = predictions_df.sort_values(by='toxicity_probability', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c25cacf5-4119-4173-b4aa-cc6218127f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity_prediction</th>\n",
       "      <th>toxicity_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Конечно, это резонансное событие требует отдельного треда для обсуждения и 19 тредов до этого шло обсуждение. Тред назывался нейтрально Рассстрел мусульман в новозеландской мечети . Но сегодня ОП, по совместительству борец за Арийскую Раssy и мамкин фашик назвал его в честь стрелка KEBAB REMOVER(англ. уничтожитель чурок ) и с утра пораньше решил в ОП-посте(заголовке треда) обозначить тред, как героизирующий(в первом треде) и оправдывающий(в третьем треде) терракт этого стрелка. Пик стронгли релейтед. 20 тред. В третьей строке заголовка ОП восхваляет и героизирует террориста, цитирую заголовок: KEBAB REMOVER тред 20 Продолжаем пиздеть тут. Слава Герою! Я репортил тред в форме репорта и в прикрепе в d , реакции никакой. Видимо, школомодеры сами симпатизируют нацизму и закрывают на это глаза. 21 тред. После того, как я пригрозил ему репортом, в этот раз мамкин фашик, убирает строку про героя и зачем-то вместо неё ставит нацистское приветствие дивизии СС Галичина. KEBAB REMOVER тред 21 Продолжаем пиздеть тут. Слава Украiнi! 22 тред. В этот раз тот же остроумный ОП поставил на третью строчку PRESS R TO PAY RESPECT!(англ. Нажмите R, чтобы выразить уважение!) т.е. уважение стрелку за то, что он совершил терракт. Еще он выделил жирным шрифтом предложение Именно эту мечеть он выбрал потому, что на её месте раньше находилась церковь. , будто то бы для оправдания стрелка. KEBAB REMOVER тред 22 Продолжаем пиздеть тут. PRESS R TO PAY RESPECT! Эти действия подпадают под конкретные статьи УК РФ, (публичное оправдание терроризма или пропаганда терроризма), а модерация никак не трёт такие заголовки треда, не реагирует на репорты. Да, я понимаю, что на Дваче возможна любая точка зрения, но хотя бы шапка треда должна быть нейтральной и уж точно не должна оправдывать и героизировать терроризм фашизм и не нарушать законодательство. Такое название треда автоматически собирает в нём нацистскую падаль и сворачивает обсуждение в сторону фашистской идеологии.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Нет, пожалуй, отвечу развернутее. Представь, что тебя ограбили. Ты идешь в частную полицию, выкладываешь бабки на стол, говоришь о случившемся. Полицаи по мере своих сил расследуют инцидент. Они дают тебе список потенциальных преступников, вероятнее всего, из одного человека. Ты приходишь к человеку, говоришь, так и так, чувак, я тебя подозреваю, хочу судиться. Если он тоже хочет судиться, то он идет с тобой в выбранный вами обоими суд. Если не хочет, то ты обращаешься в суд со своей доказательной базой, он приходит к человеку и обращается с подобной фразой: вы, гражданин такой-то такой-то, обвиняетесь по тому-то тому-то. Пройдите с нами в зал суда для разбирательств, или мы, согласно статье такой-то такой-то действующего законодательства имеем право вас наказать. Если человек соглашается, то вы судитесь. Если он виновен, то ему назначается наказание и он оплачивает издержки суда, если нет, то ты оплачиваешь издержки суда и идешь искать преступника дальше силами частной полиции. Звучит пиздец как плохо, да? Ну так вот, РЫНОЧЕК ПОРЕШАЕТ так, чтобы все работало куда эффективнее. Вместо хождения по частным полицейским бюро ты, скорее всего, возьмешь у одного или нескольких из них страховку на случай примененных в твою сторону правонарушений. Для них профит в том, что они будут стабильно получать от тебя бабки, для тебя - в том, что ты можешь спать спокойно. Сами частные полицаи уже заключают контракты с судами, чтобы избежать анальной ебли с твоим хождением туда-сюда, взамен они сами ходят по предполагаемым преступникам и предлагают им пройти судиться. На самом рынке останутся наиболее эффективные суды и полицаи, потому что неэффективным никто не захочет заносить бабки. Остается вопрос: в чем тебе профит ходить в суд, если ты в жизни и мухи не обидел, кроме избежания наказания, которого ты и не заслуживаешь? И даже это порешает рыночек, потому что, очевидно, суды, которые компенсируют или даже поощряют тебя за то, чтобы ты к ним ходил, даже если ты невиновен, будут выглядеть более привлекательно. Надеюсь, на вопрос я ответил. К слову, продажные суды не будут популярны как раз из-за своей продажности, потому что выгоду от этого получает только искодатель, и то только тогда, когда дает иск ни за что. А государство из судов не вырастет как раз потому, что сами суды не будут обладать оружием, им будут обладать полицаи. Ну и конкуренция, опять же. Апелляции подавать в высшие суды, которые будут работать по тем же принципам.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Что ты несешь? ты поехавший? Ты понимаешь чем к примеру физичиеские законы отличаются от теорий разной степени охуительности ? Закон гравитации работет на всей планете Земля независимо от твоих манятеорий. Пространство блядь- трехмерно. А ты утверждаешь что оно может быть , 5,6 и прочее мерным, но доказать и продемонстрировать мы не можем по этому представим... Ты ты тупой верун Есть невидимый мужик , доказать и подтвердить мы не можем но давайте поверим... Иди нахуй. Ты настолько туп что не понимаешь даже что время- это иллюзия.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Ебать, кто смотрит сыромятникова?? Где еще можно найти настолько отталкивающий тембр голоса и манеру говорить?? Блять а полезный контент в стиле - сейчас я покажу как играть на гитаре с автотюном - который уже давно был у западников? А его охуенные видео как сделать песдатый звук, где звук выхожит полным мутным говном, потому что он напрямую в дешевую звуковую карту играет? А его бородка ебаная?? Что это блять? А блять когда он палится с подложенной аудиодорожкой когда играет на камеру, причём блять настолько нелепо, что даже видео заметно замедляет, чтобы попадало в звук, а потом говорит, что так оно все и задумано? А его блять гиперкривляния и гримасы во время игры?? Что это за пиздец? Видно же, что специально старается показать ДУШУ , которой у него на самом деле нет!! Блять у меня такой испанский стыд со всей этой хуйни ебаный в рот! Теперь еще у него будет ебанутая истеричка-жена, которая его уже загнала под неебический каблук, и будет его уничтожать окончательно. Бляя она тоже хороша. Поет мягко говоря, МЯГКО ГОВОРЯ не всегда хорошо(об этом еще Зилков мягко намекал, в его способностях никто не сомневается), зато при любом удобном случае говорит о том, что у нее неебичское ололо образование, охуенный опыт в педагогический, в ответ на сомнения в ее способностях певческих она сделала попытку страйка по авторским правам, ЗАСТАВИВ ЕЩЕ ДВУХ МУЖИКОВ ТОЖЕ ЕЕ СДЕЛАТЬ , а когда закономерно соснула, устроила истерический стрим, где стуча руками по столу на полном серьезе человека сравнивала с БАНЫМ ГИТЛЕРОМ БЛЯТЬ , который миллионами уничтожал людей ирл, а не в ютубе, затем приправив все охуительной порцией слез и соплей под омежные кукареки своего муженька? Блять это что за фантасмагория нахуй? Is this the real life?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Несправедливый раздел Русские себе почти всё забрали АХАХАХ ТУПАЯ РУСНЯ МЫ ОБЪЯВЛЯЕМ НЕЗАВИСИМОСТЬ, А ЗА ДОЛГИ И ОБЯЗАТЕЛЬСТВА БУДЕТЕ ОТВЕЧАТЬ САМИ ЛАДНО, ТОГДА МЫ ЗАБИРАЕМ И ПРАВА ПО ЭТИМ ОБЯЗАТЕЛЬСТВАМ. АХАХА ТУПАЯ РУСНЯ БЕР Т ДОЛГИ, А МЫ БУДЕМ СВОБОДНЫМИ И ЧИСТЫМИ РУСНЯ НАС ОБОБРАЛА! РУСНЯ ВС ЗАБРАЛА! Какие же нацмены дегенераты, пиздец просто. Лживый урод, все ядерное оружие из республик свезли в квазигосударство рф .И почему такие границы, зачем к рф пристегнули столько нерусских земель? Вывезли всё ядерное оружие Что такое Беловежский Договор и зачем Украина отказалась от ядерного оружия Это так теперь называется принудительное изъятие ядерного арсенала? Настолько принудительное, что на Незалежной получали деньги от США за распил самолётов Белый Лебедь с записью на камеру. Нацмен, ты прежде чем срать, попробовал хотя бы изучить историю.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Да Евген просто шлюшка без мнения - то блядь пиндосы ему плохие КОКОКО НА КРОВИ ВТОРОЙ МИРОВОЙ ПОДНЯЛИСЬ (намекая на поставки оружия совкам за бабки, только если бы не муриканское вооружение - сосали бы мы все сейчас длинный болт товарища фюрера) То блядь совки ему плохие - сплошная гебня и гулаги, то сука СОВКИ ХОРОШИЕ КОКОКО - НЕПРАВДА НЕ ВСЯ СТРАНА ГУЛАГ. СУКА АЖ ТРЯСЕТ. А споледний обзор - это вообще КРУЖКА - ЛУКЪЯНЕНКО КОКОКО ВЕЛИЧАЙШИЙ ФАНТАСТ СОВРЕМЕННОСТИ Я ЕЩЕ В 2005 НА НЕГО ДРОЧИЛ ПОКА ЭТО НЕ БЫЛО МЭЙНСТРИМОМ КАК ВАМ НЕ СТЫДНО ЗЛОСТНЫЕ КИНОДЕЛЫ ОБСИРАТЬ И ПОГАНИТЬ ТВОРЧЕСТВО ЭТОГО ВЕЛИКОГО ЧЕЛОВЕКА О ЛУКЪЯНЕНКО КОКОКО КОКОКО ДАЙТЕ Я ЕМУ ОТСОСУ и сука тутже через 15 минут АЙ АЙ АЙ АВТОР САМ ОДОБРИЛ ВСЕ ОТКЛОНЕНИЯ ОТ СУЖЕТА КНИГИ КАК НИХОРОШО АЙ АЙ АЙ - но даже тут побоялся сказать прямо - Лукъяненко продался - нет он увиливает и юлит как змея, ак червь, как червь ПИДОР. БЭДКОМЕДИАН - хуже червя ПИДОРА\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>В Киеве на вокзале Мен було рок в 19, коли мене перший раз мав в зад хлопець рок в п д 30. Я тод перш рази став заходити на вокзал Ки в-Пасажирський в туалети - де були каб ни з д рками написи на ст нах. Так як досв ду ще не було н якого, то як знайомиться не уявляв. Сам перший природно не п дходив. А видивлявся на написи. дрочив св й член стоячи в каб нц . Хлопець був у сус дн й каб нц , в н побачив це, хитнув мен головою, запрошуючи п ти з ним. А так як н кого б льше в той момент не було, а був уже веч р, над на щось нше не було -все ж п шов за ним. У мене вже тод з явилася молофья - я вже спускав. Так як трохи ран ше ще не було, при дрочц робив це до при много стану - коли просто ставало дуже добре - але з хуя н чого не вид лялося. А до цього мен вже к лька раз в смоктали член хлопц мужики, я спускав м в рот, знав як це при мно. Ми прийшли б ля вокзалу кудись в кущ . В н розстебнув мен мотню, д став м й член став дрочити. А в той час нав ть це - коли хтось чужий рукою просто всього лише дрочив мен - було все одно дуже при мно. забирало. Бо коли тоб дрочать чужою рукою в дитинств - це вже щось: в д цього балд ш дуже. В н, ймов рно, здогадуючись, що перед ним зовс м новачок не намагався нав ть мен св й дати в руку: Так в н мене зав в , а пот м попросив повернутися: Я запитав нав що, справд не розум ючи нав що - а в н сказав треба так. я як теля повернувся п дкоряючись команд дорослого. В н приспустив мен штани, труси приставив до дерева у якого ми стояли, трохи нагнувши мене. А сам встав ззаду. По звуках я зрозум в, що в н розст ба соб свою мотню д ста св й член. В н притулився до мо поп сво м хуем, в д чого я здригнувся, але в н взяв мене за м й член знову став дрочити. А ншою рукою водити по стегнах з внутр шньо сторони. П д ймаючись в д кол н до поп - це посилювало кайф в д дрочк , я мл в, в н це теж в дчував, вже спок йно став тертися сво м хуем мен по поп . Пот м в н перестав дрочити мен , я почув як в н послинив св й член мою д рочку приставив мен св й член, в дсунув мене в д дерева трохи, пригнув мене почав засовували член в мене. Я стояв нагнувшись, упершись руками в дерево, н живий, н мертвий - перший раз в житт хлопець в мене засовував св й хуй! Я боявся - як все буде, що буде з мною, як це. Мен пощастило, звичайно, для першого разу, що у нього був маленький тонкий хуй. Тому н яких проблем у нього з всуванням його хуя в мою св жу попку не було. Оск льки мен не було боляче або непри мно я стояв не с паючись. Чекаючи як що буде дал :. В н засунув св й член весь в мене. т льки коли в н встромив його до к нця - було в дчуття що в н у щось уперся. Але не боляче зовс м. треба сказати чесно, що було при мно в дчувати, коли яйця його доторкнулися до мо попки, до д рочки, коли весь член був уже всередин не .. Це при мне в дчуття, коли умоглядно уявля ш що в тебе чийсь член засунуть: Це було мабуть нав ть при мн ше н ж все нше - в дчувати його яйця б ля очка. Коли весь член вже там. коли в н пот м став й бати мене, я намагався щоб част ше яйця його впиралися в попу мен , нав ть нод насаджувався сам глибше на його член, до упору. Але показувати що мен щось при мно тод здавалося ще не зручним - б льший час я просто стояв обхопивши дерево руками, а в н вставляв член в мене. Хоча особливого кайфу я ще тод не в дчував - було в дчуття - що просто в мене встромляв хлопець св й член ходив там. Так в н мав мене, продовжуючи одночасно весь цей час одн ю рукою дрочить мен - п дтримуючи в мен бажання: - ось в д цього мен було при мно. Природно. Це був його розрахунок. Я досить швидко в д дрочк чужою рукою спустив, в дразу з скочив з його члена. Але в дчув що у мене щось липкою ззаду на стегнах: Що щось тече по стегнах з очка. ось це мене засмутило сильно. вбило - я здогадався зрозум в що в н спустив в мене. Запитав, - Ти що ск нчив у мене? в н сказав - так. запитав мене - а ти що перший раз це робив? я мало не плачучи в д образи сказав - що так, перший раз: поставив йому дурне питання - нав що ти в мене спустив? Я не припускав цього, думав що в н просто посует ться в мене св й хуй все, а тут мен стало не по соб : було огидно, - особливо п сля того як сам пустив, - що на мен чужа гидота , як тод сприймав чужу малофю . Та тим б льше на сво му т л . Але справа була зроблена: хлопця 19 рок в видрали в дупу! спустили сперму йому в очко! В струнку, пружну, н жну попочку з н жною д рочкою, засунувши в не перший раз член! У перший момент було огидно в д того що щось липке, спочатку тепле, ст кало по стегнах, а пот м застигло так: (а так як не готувався до цього, то витерти було н чим:) Тод було прикро, не за те що ви бав, а що не попередивши, спустив в мене. Так як тод сперма сприймалася як щось мерзенне, тим б льше на соб . Пот м згадував про це вже з та мним насолодою, нав ть бажанням, щоб це повторилося: я поб г швидко з цього м сця, скор ше в д нього, а липка р дина на стегнах весь час нагадувала, що мене т льки що ви бли в жопу. Слава Укра н !</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>лахтадырые и ольгинцы (Лахта, Ольгино) это которые провластные комменты пишут, мол у пендосов еще хуже, в европе пидоры. В рунете дохуя еще киберсотенцев - это хохляцкие ципсо, у них несколько этих самых ципсо, 72-е и 74-е в основном на дваче. Пишут по-русски, как правило от лица русских, создают вбросы, фейкньюс и так далее. Пишут какие же хохлы молодцы, их уже в европу взяли, нам надо им Крым отдать вместе с Кубанью и покаяться. Им американцы еще денежкой помогают, они работают в их интересах и сходят за русских. Хотя часто палятся, пишут через дефис, буква е вместо э , и т.д. Ну есть еще редакторы соцсетей из ФБК - это самые дно, тупые малолетние студентики мечтающие о борьбе против системы, они, как првило, даже забесплатно работают, волонтеры, короче. Пишут как в рашке хуево жить, банду путина долой, и т.д. Их называют окатышами.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>нету. В тех же США большинство негров-мужчин были судимы. Пидораха, ты определись, у тебя речь о мигрантах или таких же коренных полноправных гражданах-неграх? ты еслибыкаешь да баттхертишь оп принёс пруфы скриншот газеты уровня СПИД-инфо хач-вампир выебал ЗЭКА Я же не svin ja чтобы копаться в желтушном мусоре и тащить всё сюда в тред. Вон есть всякие паблики новости русского мира , наслаждайся пруфами там.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ БЛЯДЬ, Я НА ТРУБУ ЗАХОЖУ ТОЛЬКО САУНДТРЕКИ ИЗ ФИЛЬМ И ИГОР ПОСЛУШАТЬ. ЧТОБ ВАШЕГО АЙТИПЕДИЮ РАСКАЛЕННЫМИ КОЧЕРГАМИ В ЖОПУ ШПИОН ОТ ГУГОЛА ЕБАЛ, БЛЯДЬ. ЭТО ЖЕ ВСЕ ИЗ-ЗА ТОГО, ЧТО Я НА ХРЮ ЗАШЕЛ ПО НАВОДКЕ АБУ, ДА? МЕЙЛААААААААААААААААААААААААААААААЧ\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "941                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Конечно, это резонансное событие требует отдельного треда для обсуждения и 19 тредов до этого шло обсуждение. Тред назывался нейтрально Рассстрел мусульман в новозеландской мечети . Но сегодня ОП, по совместительству борец за Арийскую Раssy и мамкин фашик назвал его в честь стрелка KEBAB REMOVER(англ. уничтожитель чурок ) и с утра пораньше решил в ОП-посте(заголовке треда) обозначить тред, как героизирующий(в первом треде) и оправдывающий(в третьем треде) терракт этого стрелка. Пик стронгли релейтед. 20 тред. В третьей строке заголовка ОП восхваляет и героизирует террориста, цитирую заголовок: KEBAB REMOVER тред 20 Продолжаем пиздеть тут. Слава Герою! Я репортил тред в форме репорта и в прикрепе в d , реакции никакой. Видимо, школомодеры сами симпатизируют нацизму и закрывают на это глаза. 21 тред. После того, как я пригрозил ему репортом, в этот раз мамкин фашик, убирает строку про героя и зачем-то вместо неё ставит нацистское приветствие дивизии СС Галичина. KEBAB REMOVER тред 21 Продолжаем пиздеть тут. Слава Украiнi! 22 тред. В этот раз тот же остроумный ОП поставил на третью строчку PRESS R TO PAY RESPECT!(англ. Нажмите R, чтобы выразить уважение!) т.е. уважение стрелку за то, что он совершил терракт. Еще он выделил жирным шрифтом предложение Именно эту мечеть он выбрал потому, что на её месте раньше находилась церковь. , будто то бы для оправдания стрелка. KEBAB REMOVER тред 22 Продолжаем пиздеть тут. PRESS R TO PAY RESPECT! Эти действия подпадают под конкретные статьи УК РФ, (публичное оправдание терроризма или пропаганда терроризма), а модерация никак не трёт такие заголовки треда, не реагирует на репорты. Да, я понимаю, что на Дваче возможна любая точка зрения, но хотя бы шапка треда должна быть нейтральной и уж точно не должна оправдывать и героизировать терроризм фашизм и не нарушать законодательство. Такое название треда автоматически собирает в нём нацистскую падаль и сворачивает обсуждение в сторону фашистской идеологии.\\n   \n",
       "483                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Нет, пожалуй, отвечу развернутее. Представь, что тебя ограбили. Ты идешь в частную полицию, выкладываешь бабки на стол, говоришь о случившемся. Полицаи по мере своих сил расследуют инцидент. Они дают тебе список потенциальных преступников, вероятнее всего, из одного человека. Ты приходишь к человеку, говоришь, так и так, чувак, я тебя подозреваю, хочу судиться. Если он тоже хочет судиться, то он идет с тобой в выбранный вами обоими суд. Если не хочет, то ты обращаешься в суд со своей доказательной базой, он приходит к человеку и обращается с подобной фразой: вы, гражданин такой-то такой-то, обвиняетесь по тому-то тому-то. Пройдите с нами в зал суда для разбирательств, или мы, согласно статье такой-то такой-то действующего законодательства имеем право вас наказать. Если человек соглашается, то вы судитесь. Если он виновен, то ему назначается наказание и он оплачивает издержки суда, если нет, то ты оплачиваешь издержки суда и идешь искать преступника дальше силами частной полиции. Звучит пиздец как плохо, да? Ну так вот, РЫНОЧЕК ПОРЕШАЕТ так, чтобы все работало куда эффективнее. Вместо хождения по частным полицейским бюро ты, скорее всего, возьмешь у одного или нескольких из них страховку на случай примененных в твою сторону правонарушений. Для них профит в том, что они будут стабильно получать от тебя бабки, для тебя - в том, что ты можешь спать спокойно. Сами частные полицаи уже заключают контракты с судами, чтобы избежать анальной ебли с твоим хождением туда-сюда, взамен они сами ходят по предполагаемым преступникам и предлагают им пройти судиться. На самом рынке останутся наиболее эффективные суды и полицаи, потому что неэффективным никто не захочет заносить бабки. Остается вопрос: в чем тебе профит ходить в суд, если ты в жизни и мухи не обидел, кроме избежания наказания, которого ты и не заслуживаешь? И даже это порешает рыночек, потому что, очевидно, суды, которые компенсируют или даже поощряют тебя за то, чтобы ты к ним ходил, даже если ты невиновен, будут выглядеть более привлекательно. Надеюсь, на вопрос я ответил. К слову, продажные суды не будут популярны как раз из-за своей продажности, потому что выгоду от этого получает только искодатель, и то только тогда, когда дает иск ни за что. А государство из судов не вырастет как раз потому, что сами суды не будут обладать оружием, им будут обладать полицаи. Ну и конкуренция, опять же. Апелляции подавать в высшие суды, которые будут работать по тем же принципам.\\n   \n",
       "210                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Что ты несешь? ты поехавший? Ты понимаешь чем к примеру физичиеские законы отличаются от теорий разной степени охуительности ? Закон гравитации работет на всей планете Земля независимо от твоих манятеорий. Пространство блядь- трехмерно. А ты утверждаешь что оно может быть , 5,6 и прочее мерным, но доказать и продемонстрировать мы не можем по этому представим... Ты ты тупой верун Есть невидимый мужик , доказать и подтвердить мы не можем но давайте поверим... Иди нахуй. Ты настолько туп что не понимаешь даже что время- это иллюзия.\\n   \n",
       "976                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Ебать, кто смотрит сыромятникова?? Где еще можно найти настолько отталкивающий тембр голоса и манеру говорить?? Блять а полезный контент в стиле - сейчас я покажу как играть на гитаре с автотюном - который уже давно был у западников? А его охуенные видео как сделать песдатый звук, где звук выхожит полным мутным говном, потому что он напрямую в дешевую звуковую карту играет? А его бородка ебаная?? Что это блять? А блять когда он палится с подложенной аудиодорожкой когда играет на камеру, причём блять настолько нелепо, что даже видео заметно замедляет, чтобы попадало в звук, а потом говорит, что так оно все и задумано? А его блять гиперкривляния и гримасы во время игры?? Что это за пиздец? Видно же, что специально старается показать ДУШУ , которой у него на самом деле нет!! Блять у меня такой испанский стыд со всей этой хуйни ебаный в рот! Теперь еще у него будет ебанутая истеричка-жена, которая его уже загнала под неебический каблук, и будет его уничтожать окончательно. Бляя она тоже хороша. Поет мягко говоря, МЯГКО ГОВОРЯ не всегда хорошо(об этом еще Зилков мягко намекал, в его способностях никто не сомневается), зато при любом удобном случае говорит о том, что у нее неебичское ололо образование, охуенный опыт в педагогический, в ответ на сомнения в ее способностях певческих она сделала попытку страйка по авторским правам, ЗАСТАВИВ ЕЩЕ ДВУХ МУЖИКОВ ТОЖЕ ЕЕ СДЕЛАТЬ , а когда закономерно соснула, устроила истерический стрим, где стуча руками по столу на полном серьезе человека сравнивала с БАНЫМ ГИТЛЕРОМ БЛЯТЬ , который миллионами уничтожал людей ирл, а не в ютубе, затем приправив все охуительной порцией слез и соплей под омежные кукареки своего муженька? Блять это что за фантасмагория нахуй? Is this the real life?\\n   \n",
       "57                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Несправедливый раздел Русские себе почти всё забрали АХАХАХ ТУПАЯ РУСНЯ МЫ ОБЪЯВЛЯЕМ НЕЗАВИСИМОСТЬ, А ЗА ДОЛГИ И ОБЯЗАТЕЛЬСТВА БУДЕТЕ ОТВЕЧАТЬ САМИ ЛАДНО, ТОГДА МЫ ЗАБИРАЕМ И ПРАВА ПО ЭТИМ ОБЯЗАТЕЛЬСТВАМ. АХАХА ТУПАЯ РУСНЯ БЕР Т ДОЛГИ, А МЫ БУДЕМ СВОБОДНЫМИ И ЧИСТЫМИ РУСНЯ НАС ОБОБРАЛА! РУСНЯ ВС ЗАБРАЛА! Какие же нацмены дегенераты, пиздец просто. Лживый урод, все ядерное оружие из республик свезли в квазигосударство рф .И почему такие границы, зачем к рф пристегнули столько нерусских земель? Вывезли всё ядерное оружие Что такое Беловежский Договор и зачем Украина отказалась от ядерного оружия Это так теперь называется принудительное изъятие ядерного арсенала? Настолько принудительное, что на Незалежной получали деньги от США за распил самолётов Белый Лебедь с записью на камеру. Нацмен, ты прежде чем срать, попробовал хотя бы изучить историю.\\n   \n",
       "1050                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Да Евген просто шлюшка без мнения - то блядь пиндосы ему плохие КОКОКО НА КРОВИ ВТОРОЙ МИРОВОЙ ПОДНЯЛИСЬ (намекая на поставки оружия совкам за бабки, только если бы не муриканское вооружение - сосали бы мы все сейчас длинный болт товарища фюрера) То блядь совки ему плохие - сплошная гебня и гулаги, то сука СОВКИ ХОРОШИЕ КОКОКО - НЕПРАВДА НЕ ВСЯ СТРАНА ГУЛАГ. СУКА АЖ ТРЯСЕТ. А споледний обзор - это вообще КРУЖКА - ЛУКЪЯНЕНКО КОКОКО ВЕЛИЧАЙШИЙ ФАНТАСТ СОВРЕМЕННОСТИ Я ЕЩЕ В 2005 НА НЕГО ДРОЧИЛ ПОКА ЭТО НЕ БЫЛО МЭЙНСТРИМОМ КАК ВАМ НЕ СТЫДНО ЗЛОСТНЫЕ КИНОДЕЛЫ ОБСИРАТЬ И ПОГАНИТЬ ТВОРЧЕСТВО ЭТОГО ВЕЛИКОГО ЧЕЛОВЕКА О ЛУКЪЯНЕНКО КОКОКО КОКОКО ДАЙТЕ Я ЕМУ ОТСОСУ и сука тутже через 15 минут АЙ АЙ АЙ АВТОР САМ ОДОБРИЛ ВСЕ ОТКЛОНЕНИЯ ОТ СУЖЕТА КНИГИ КАК НИХОРОШО АЙ АЙ АЙ - но даже тут побоялся сказать прямо - Лукъяненко продался - нет он увиливает и юлит как змея, ак червь, как червь ПИДОР. БЭДКОМЕДИАН - хуже червя ПИДОРА\\n   \n",
       "265   В Киеве на вокзале Мен було рок в 19, коли мене перший раз мав в зад хлопець рок в п д 30. Я тод перш рази став заходити на вокзал Ки в-Пасажирський в туалети - де були каб ни з д рками написи на ст нах. Так як досв ду ще не було н якого, то як знайомиться не уявляв. Сам перший природно не п дходив. А видивлявся на написи. дрочив св й член стоячи в каб нц . Хлопець був у сус дн й каб нц , в н побачив це, хитнув мен головою, запрошуючи п ти з ним. А так як н кого б льше в той момент не було, а був уже веч р, над на щось нше не було -все ж п шов за ним. У мене вже тод з явилася молофья - я вже спускав. Так як трохи ран ше ще не було, при дрочц робив це до при много стану - коли просто ставало дуже добре - але з хуя н чого не вид лялося. А до цього мен вже к лька раз в смоктали член хлопц мужики, я спускав м в рот, знав як це при мно. Ми прийшли б ля вокзалу кудись в кущ . В н розстебнув мен мотню, д став м й член став дрочити. А в той час нав ть це - коли хтось чужий рукою просто всього лише дрочив мен - було все одно дуже при мно. забирало. Бо коли тоб дрочать чужою рукою в дитинств - це вже щось: в д цього балд ш дуже. В н, ймов рно, здогадуючись, що перед ним зовс м новачок не намагався нав ть мен св й дати в руку: Так в н мене зав в , а пот м попросив повернутися: Я запитав нав що, справд не розум ючи нав що - а в н сказав треба так. я як теля повернувся п дкоряючись команд дорослого. В н приспустив мен штани, труси приставив до дерева у якого ми стояли, трохи нагнувши мене. А сам встав ззаду. По звуках я зрозум в, що в н розст ба соб свою мотню д ста св й член. В н притулився до мо поп сво м хуем, в д чого я здригнувся, але в н взяв мене за м й член знову став дрочити. А ншою рукою водити по стегнах з внутр шньо сторони. П д ймаючись в д кол н до поп - це посилювало кайф в д дрочк , я мл в, в н це теж в дчував, вже спок йно став тертися сво м хуем мен по поп . Пот м в н перестав дрочити мен , я почув як в н послинив св й член мою д рочку приставив мен св й член, в дсунув мене в д дерева трохи, пригнув мене почав засовували член в мене. Я стояв нагнувшись, упершись руками в дерево, н живий, н мертвий - перший раз в житт хлопець в мене засовував св й хуй! Я боявся - як все буде, що буде з мною, як це. Мен пощастило, звичайно, для першого разу, що у нього був маленький тонкий хуй. Тому н яких проблем у нього з всуванням його хуя в мою св жу попку не було. Оск льки мен не було боляче або непри мно я стояв не с паючись. Чекаючи як що буде дал :. В н засунув св й член весь в мене. т льки коли в н встромив його до к нця - було в дчуття що в н у щось уперся. Але не боляче зовс м. треба сказати чесно, що було при мно в дчувати, коли яйця його доторкнулися до мо попки, до д рочки, коли весь член був уже всередин не .. Це при мне в дчуття, коли умоглядно уявля ш що в тебе чийсь член засунуть: Це було мабуть нав ть при мн ше н ж все нше - в дчувати його яйця б ля очка. Коли весь член вже там. коли в н пот м став й бати мене, я намагався щоб част ше яйця його впиралися в попу мен , нав ть нод насаджувався сам глибше на його член, до упору. Але показувати що мен щось при мно тод здавалося ще не зручним - б льший час я просто стояв обхопивши дерево руками, а в н вставляв член в мене. Хоча особливого кайфу я ще тод не в дчував - було в дчуття - що просто в мене встромляв хлопець св й член ходив там. Так в н мав мене, продовжуючи одночасно весь цей час одн ю рукою дрочить мен - п дтримуючи в мен бажання: - ось в д цього мен було при мно. Природно. Це був його розрахунок. Я досить швидко в д дрочк чужою рукою спустив, в дразу з скочив з його члена. Але в дчув що у мене щось липкою ззаду на стегнах: Що щось тече по стегнах з очка. ось це мене засмутило сильно. вбило - я здогадався зрозум в що в н спустив в мене. Запитав, - Ти що ск нчив у мене? в н сказав - так. запитав мене - а ти що перший раз це робив? я мало не плачучи в д образи сказав - що так, перший раз: поставив йому дурне питання - нав що ти в мене спустив? Я не припускав цього, думав що в н просто посует ться в мене св й хуй все, а тут мен стало не по соб : було огидно, - особливо п сля того як сам пустив, - що на мен чужа гидота , як тод сприймав чужу малофю . Та тим б льше на сво му т л . Але справа була зроблена: хлопця 19 рок в видрали в дупу! спустили сперму йому в очко! В струнку, пружну, н жну попочку з н жною д рочкою, засунувши в не перший раз член! У перший момент було огидно в д того що щось липке, спочатку тепле, ст кало по стегнах, а пот м застигло так: (а так як не готувався до цього, то витерти було н чим:) Тод було прикро, не за те що ви бав, а що не попередивши, спустив в мене. Так як тод сперма сприймалася як щось мерзенне, тим б льше на соб . Пот м згадував про це вже з та мним насолодою, нав ть бажанням, щоб це повторилося: я поб г швидко з цього м сця, скор ше в д нього, а липка р дина на стегнах весь час нагадувала, що мене т льки що ви бли в жопу. Слава Укра н !   \n",
       "203                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            лахтадырые и ольгинцы (Лахта, Ольгино) это которые провластные комменты пишут, мол у пендосов еще хуже, в европе пидоры. В рунете дохуя еще киберсотенцев - это хохляцкие ципсо, у них несколько этих самых ципсо, 72-е и 74-е в основном на дваче. Пишут по-русски, как правило от лица русских, создают вбросы, фейкньюс и так далее. Пишут какие же хохлы молодцы, их уже в европу взяли, нам надо им Крым отдать вместе с Кубанью и покаяться. Им американцы еще денежкой помогают, они работают в их интересах и сходят за русских. Хотя часто палятся, пишут через дефис, буква е вместо э , и т.д. Ну есть еще редакторы соцсетей из ФБК - это самые дно, тупые малолетние студентики мечтающие о борьбе против системы, они, как првило, даже забесплатно работают, волонтеры, короче. Пишут как в рашке хуево жить, банду путина долой, и т.д. Их называют окатышами.\\n   \n",
       "70                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 нету. В тех же США большинство негров-мужчин были судимы. Пидораха, ты определись, у тебя речь о мигрантах или таких же коренных полноправных гражданах-неграх? ты еслибыкаешь да баттхертишь оп принёс пруфы скриншот газеты уровня СПИД-инфо хач-вампир выебал ЗЭКА Я же не svin ja чтобы копаться в желтушном мусоре и тащить всё сюда в тред. Вон есть всякие паблики новости русского мира , наслаждайся пруфами там.\\n   \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ БЛЯДЬ, Я НА ТРУБУ ЗАХОЖУ ТОЛЬКО САУНДТРЕКИ ИЗ ФИЛЬМ И ИГОР ПОСЛУШАТЬ. ЧТОБ ВАШЕГО АЙТИПЕДИЮ РАСКАЛЕННЫМИ КОЧЕРГАМИ В ЖОПУ ШПИОН ОТ ГУГОЛА ЕБАЛ, БЛЯДЬ. ЭТО ЖЕ ВСЕ ИЗ-ЗА ТОГО, ЧТО Я НА ХРЮ ЗАШЕЛ ПО НАВОДКЕ АБУ, ДА? МЕЙЛААААААААААААААААААААААААААААААЧ\\n   \n",
       "\n",
       "      toxicity_prediction  toxicity_probability  \n",
       "941                   1.0                   1.0  \n",
       "483                   1.0                   1.0  \n",
       "210                   1.0                   1.0  \n",
       "976                   1.0                   1.0  \n",
       "57                    1.0                   1.0  \n",
       "1050                  1.0                   1.0  \n",
       "265                   1.0                   1.0  \n",
       "203                   1.0                   1.0  \n",
       "70                    1.0                   1.0  \n",
       "36                    1.0                   1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "top_10_toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a20204-9484-4a7a-b2e1-40b0379dfd1e",
   "metadata": {},
   "source": [
    "Почему-то toxicity_probability для некоторых текстов здесь 100 процентная, выглядит подозрительно. Я не поняла, с чем связана такая высокая степень уверенности модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e67b56-c4cc-459b-83e9-1439e1963704",
   "metadata": {},
   "source": [
    "### 2. TfidfVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa11d91-35ff-4315-a71d-0c50e1fb2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b06798-cb1d-40ff-8b8f-3a826be951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_russian = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57da0c58-4ccd-4a47-8b67-4d22146d03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(max_features=9000, min_df=4, max_df=0.5, ngram_range=(1, 2), stop_words=stop_words_russian)\n",
    "X = tfidfvectorizer.fit_transform(train.comment)\n",
    "X_test = tfidfvectorizer.transform(test.comment)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a66a4f-e264-44a9-9a24-29ed50a7aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.87      0.88       962\n",
      "         1.0       0.75      0.80      0.78       480\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.83      0.84      0.83      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.7, class_weight='balanced', max_iter=2000, multi_class=\"ovr\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6363a4-3003-4803-af6d-24f2c6f6bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X_test)[:, 1]\n",
    "predictions_df = pd.DataFrame({\n",
    "    'text': test['comment'],  \n",
    "    'toxicity_prediction': preds,\n",
    "    'toxicity_probability': probs\n",
    "})\n",
    "top_10_toxic = predictions_df.sort_values(by='toxicity_probability', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb01988b-57f4-4061-be26-730da3487965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity_prediction</th>\n",
       "      <th>toxicity_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>блядь, заткнись ты . я уже взлетаю нахуй.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Вы вот смеетесь, а что будет, когда у нас эти смешные хохлы закончатся?\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>соси как хохлы сосут хохол\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>У-ух, ненавижу, блядь, хохлов.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Замуж тебе надо барыня...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Но Трамп и в правда дегенерат. Жаль, что этот клоун победил и мы теперь живем в пиздеце. Блять, если бы Клинтон сейчас была у власти, то в мире не было бы такого трэша. В рот ебал промыток с альт-райтом головного мозга, вы же нихуя своей головой думать не можете, животные, мемов про сжв насмотрелись теперь строите из себя дохуя консерваторов.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>потому что хохлы - пидорашки\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Блять, маргиналошизики, чего вас так тянет сюда? Пиздуйте в свой тред и там создавайте борду с ue b er marginal\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Нахуй ты высрался тогда тут? МНЕ НИНРАВИЦА ЯСКОЗАЛ ХРЯ\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                            text  \\\n",
       "839                                                                                                                                                                                                                                                                                                    Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло\\n   \n",
       "1214                                                                                                                                                                                                                                                                                                                 блядь, заткнись ты . я уже взлетаю нахуй.\\n   \n",
       "186                                                                                                                                                                                                                                                                                    Вы вот смеетесь, а что будет, когда у нас эти смешные хохлы закончатся?\\n   \n",
       "1401                                                                                                                                                                                                                                                                                                                                соси как хохлы сосут хохол\\n   \n",
       "669                                                                                                                                                                                                                                                                                                                             У-ух, ненавижу, блядь, хохлов.\\n   \n",
       "1048                                                                                                                                                                                                                                                                                                                                 Замуж тебе надо барыня...\\n   \n",
       "1315  Но Трамп и в правда дегенерат. Жаль, что этот клоун победил и мы теперь живем в пиздеце. Блять, если бы Клинтон сейчас была у власти, то в мире не было бы такого трэша. В рот ебал промыток с альт-райтом головного мозга, вы же нихуя своей головой думать не можете, животные, мемов про сжв насмотрелись теперь строите из себя дохуя консерваторов.\\n   \n",
       "780                                                                                                                                                                                                                                                                                                                               потому что хохлы - пидорашки\\n   \n",
       "1050                                                                                                                                                                                                                                           Блять, маргиналошизики, чего вас так тянет сюда? Пиздуйте в свой тред и там создавайте борду с ue b er marginal\\n   \n",
       "659                                                                                                                                                                                                                                                                                                     Нахуй ты высрался тогда тут? МНЕ НИНРАВИЦА ЯСКОЗАЛ ХРЯ\\n   \n",
       "\n",
       "      toxicity_prediction  toxicity_probability  \n",
       "839                   1.0              0.994479  \n",
       "1214                  1.0              0.984635  \n",
       "186                   1.0              0.983661  \n",
       "1401                  1.0              0.978343  \n",
       "669                   1.0              0.978301  \n",
       "1048                  1.0              0.975246  \n",
       "1315                  1.0              0.971841  \n",
       "780                   1.0              0.971239  \n",
       "1050                  1.0              0.961476  \n",
       "659                   1.0              0.961430  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "top_10_toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e414324-42f5-4df9-a450-d8fbcb083422",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Оценка\n",
    "И там, и там комментарии токсичные, но не совпадают из-за разных векторайзеров в первую очередь, наверное. У CountVectorizer – токсичные лонгриды про политику, у Tfidf – короткие аграссивные высказывания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23baa6-c22d-45e5-8edc-c02b4f64985e",
   "metadata": {},
   "source": [
    "##### Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между',\n",
       " 'это',\n",
       " 'тебе',\n",
       " 'почему',\n",
       " 'очень',\n",
       " 'просто',\n",
       " 'например',\n",
       " 'стоит',\n",
       " 'ещё',\n",
       " 'года',\n",
       " 'знаю',\n",
       " 'время',\n",
       " 'всё',\n",
       " 'лет',\n",
       " 'вообще']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('russian'))\n",
    "# почему-то эти слова появлялись в топе токсичности у нескольких моделей, поэтому добавила их тоже в список стоп-слов\n",
    "additional_stop_words = stop_words + [\"это\", \"тебе\", \"почему\", \"очень\", \"просто\", \"например\", \"стоит\", \"ещё\", \"года\", \"знаю\", \"время\", \"всё\", \"лет\", \"вообще\"]\n",
    "additional_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cc8e8c-7130-494a-b2e5-7e2f348a4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=additional_stop_words, max_features=9000, min_df=3, max_df=0.07)\n",
    "X = vectorizer.fit_transform(train.comment) \n",
    "X_test = vectorizer.transform(test.comment)\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd236dd-c9d6-48eb-829c-475fed535d84",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d059a13-21d6-4e5f-a055-e5cffbf678b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.89       952\n",
      "         1.0       0.78      0.80      0.79       490\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.84      0.84      0.84      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "593a81ef-193a-4f89-a604-33ed0ae9787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлы', 1.6098924657473772),\n",
       " ('хохлов', 1.4739131403732524),\n",
       " ('нахуй', 1.2322095208399824),\n",
       " ('блять', 1.1448430196455224),\n",
       " ('блядь', 1.067223912226172),\n",
       " ('пиздец', 1.0594777556942567),\n",
       " ('хуй', 0.9896100748796677),\n",
       " ('сука', 0.9717789569005622),\n",
       " ('лол', 0.9317705943435961),\n",
       " ('дебил', 0.9138525707614747)]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение слов из векторизатора\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Получение коэффициентов признаков из обученной модели\n",
    "coef = lr.coef_[0]\n",
    "\n",
    "# Сопоставление слов и их важности\n",
    "feature_importance = dict(zip(feature_names, coef))\n",
    "\n",
    "# Получение топа наиболее важных токсичных слов\n",
    "top_toxic_words = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "top_toxic_words = [(word, coef) for word, coef in top_toxic_words][:10]\n",
    "top_toxic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f4ab5-ea10-4328-ba86-64a47e76d6ca",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "12976a55-7f37-4e04-ab76-2cafc154c40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.77      0.81       952\n",
      "         1.0       0.62      0.73      0.67       490\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.73      0.75      0.74      1442\n",
      "weighted avg       0.77      0.76      0.76      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=1200, class_weight='balanced')\n",
    "dtc.fit(X, y)\n",
    "preds = dtc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d9fbd7c9-27f7-40c8-aea4-14e19719407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлы', 1.6098924657473772),\n",
       " ('хохлов', 1.4739131403732524),\n",
       " ('нахуй', 1.2322095208399824),\n",
       " ('блять', 1.1448430196455224),\n",
       " ('блядь', 1.067223912226172),\n",
       " ('пиздец', 1.0594777556942567),\n",
       " ('хуй', 0.9896100748796677),\n",
       " ('сука', 0.9717789569005622),\n",
       " ('лол', 0.9317705943435961),\n",
       " ('дебил', 0.9138525707614747)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение слов из векторайзера\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Получение важности слов из классификатора\n",
    "feature_importance = dtc.feature_importances_\n",
    "\n",
    "# Сопоставление слов и их значимости, затем отбор топа наиболее важных токсичных слов\n",
    "top_toxic_words_dtc = [(feature_names[idx], importance) for idx, importance in enumerate(feature_importance)]\n",
    "top_toxic_words_dtc = sorted(top_toxic_words, key=lambda x: x[1], reverse=True)[:10]\n",
    "top_toxic_words_dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5245cbc-5b0a-4eb6-89f1-891734068565",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0f1883-557c-46bc-88ad-7a472a0aa048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       959\n",
      "         1.0       0.78      0.74      0.76       483\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.83      0.82      0.82      1442\n",
      "weighted avg       0.84      0.84      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=1, fit_prior=False)\n",
    "nb.fit(X, y)\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a616ba8-433b-49f3-897d-f73ea0a71ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-6.090361257073701, 'хохлы'),\n",
       " (-6.277617279223223, 'хохлов'),\n",
       " (-6.2779892595985345, 'нахуй'),\n",
       " (-6.545303981054182, 'блять'),\n",
       " (-6.548194340983322, 'пиздец'),\n",
       " (-6.555814690165637, 'блядь'),\n",
       " (-6.556869541119329, 'хуй'),\n",
       " (-6.592087323495406, 'тред'),\n",
       " (-6.706077945007733, 'сука'),\n",
       " (-6.813682963053642, 'лол')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение слов из векторизатора\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Получение логарифма вероятности слова для каждого класса из модели\n",
    "log_probs = nb.feature_log_prob_\n",
    "\n",
    "# Нахождение топа токсичных слов для класса 1 (токсичные комментарии)\n",
    "class_1_log_probs = log_probs[1]  # Выбор логарифмов вероятностей для класса 1\n",
    "word_probs = list(zip(class_1_log_probs, feature_names))  # Сопоставление логарифмов вероятностей и слов\n",
    "top_toxic_words_nb = sorted(word_probs, reverse=True)[:10]  # Получение топ слов с наибольшими логарифмами вероятностей\n",
    "top_toxic_words_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4737c9-c59e-4e5c-a470-a4791f46eec2",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c60071d-9fb2-441b-a198-4a5372ca46e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.64      0.74       959\n",
      "         1.0       0.53      0.81      0.64       483\n",
      "\n",
      "    accuracy                           0.70      1442\n",
      "   macro avg       0.70      0.73      0.69      1442\n",
      "weighted avg       0.76      0.70      0.71      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', max_depth=20)\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f312ad69-892b-44cc-93ec-81e6b5e8cd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлов', 0.02008077289313733),\n",
       " ('хохлы', 0.019607595071454577),\n",
       " ('нахуй', 0.017667217041182882),\n",
       " ('тред', 0.016225391255067802),\n",
       " ('блядь', 0.014238066756471204)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение слов из векторизатора\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Получение значений важности признаков из классификатора\n",
    "importances = rf.feature_importances_ \n",
    "\n",
    "# я так поняла, в RandomForest нельзя получить значимость слов для отдельных классов, только в целом\n",
    "# Сортировка индексов признаков по важности и выбор топа самых важных\n",
    "top_indices = importances.argsort()[::-1][:5]\n",
    "\n",
    "# Создание списка из топа важных слов\n",
    "top_toxic_words_rf = [(feature_names[idx], importances[idx]) for idx in top_indices]\n",
    "top_toxic_words_rf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
