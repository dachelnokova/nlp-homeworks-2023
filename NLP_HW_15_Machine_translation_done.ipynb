{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 10. Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj7aripVIsbG",
      "metadata": {
        "id": "Yj7aripVIsbG"
      },
      "source": [
        "## Задание 1 (6 баллов + 2 доп балла).\n",
        "Нужно обучить трансформер на этом же или на другом корпусе (можно взять другую языковую пару с того же сайте) и оценивать его на всей тестовой выборке (а не на 10 примерах как сделал я). Используйте метрику BLEU. Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
        "\n",
        "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [END] в текущем коде не сработает).\n",
        "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорты"
      ],
      "metadata": {
        "id": "y29NaE5VOA9W"
      },
      "id": "y29NaE5VOA9W"
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install unzip\n",
        "#!pip install torch==2.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3ljRCUxF2Yf",
        "outputId": "c9dbbb38-e8e4-4bd2-a403-2e598ded50d1"
      },
      "id": "r3ljRCUxF2Yf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install keras==3.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YL27iXo4BMk",
        "outputId": "34960c87-798c-42a1-a367-58ef00963c5e"
      },
      "id": "9YL27iXo4BMk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==3.1.1 in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.1.1) (4.10.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.1.1) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import keras\n",
        "import torch\n",
        "print(keras.__version__)\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFudgpSgF8cQ",
        "outputId": "8d81fef4-65c9-4310-adab-c8a19db67fa6"
      },
      "id": "tFudgpSgF8cQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1.1\n",
            "2.0.1+cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install tokenizers matplotlib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7B6u4DpF--Q",
        "outputId": "5dd9f543-0006-4a12-e01b-7a3afa252219"
      },
      "id": "V7B6u4DpF--Q",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "MQobDqe-Gowt"
      },
      "id": "MQobDqe-Gowt",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Данные\n",
        "\n",
        "Данные взяты вот отсюда - https://opus.nlpl.eu/opus-100.php (раздел с отдельными языковыми парами)"
      ],
      "metadata": {
        "id": "75BjJfxjOEro"
      },
      "id": "75BjJfxjOEro"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvKYMDlG2CM",
        "outputId": "ee535c50-5244-45c6-adbb-e05491316704"
      },
      "id": "oJvKYMDlG2CM",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-04 11:32:21--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru.1’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  92.4MB/s    in 1.3s    \n",
            "\n",
            "2024-04-04 11:32:22 (92.4 MB/s) - ‘opus.en-ru-train.ru.1’ saved [121340806/121340806]\n",
            "\n",
            "--2024-04-04 11:32:22--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en.1’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  85.8MB/s    in 0.8s    \n",
            "\n",
            "2024-04-04 11:32:23 (85.8 MB/s) - ‘opus.en-ru-train.en.1’ saved [67760131/67760131]\n",
            "\n",
            "--2024-04-04 11:32:23--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru.2’\n",
            "\n",
            "opus.en-ru-test.ru. 100%[===================>] 298.50K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-04-04 11:32:23 (3.39 MB/s) - ‘opus.en-ru-test.ru.2’ saved [305669/305669]\n",
            "\n",
            "--2024-04-04 11:32:23--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en.2’\n",
            "\n",
            "opus.en-ru-test.en. 100%[===================>] 169.25K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-04-04 11:32:24 (2.57 MB/s) - ‘opus.en-ru-test.en.2’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в русскоязычных данных есть \\xa0 вместо пробелов, он может некорректно обрабатываться токенизатором\n",
        "text = open('opus.en-ru-train.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-train.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "cJD9YASGHABT"
      },
      "id": "cJD9YASGHABT",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "czcYND8fHBrW"
      },
      "id": "czcYND8fHBrW",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eb9b498",
        "outputId": "20ab0959-b102-4719-a925-22856620f76d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('so what are you thinking?', 'ну и что ты думаешь?')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Пример перевода с английского на русский\n",
        "en_sents[-1], ru_sents[-1]"
      ],
      "id": "0eb9b498"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизаторы"
      ],
      "metadata": {
        "id": "vV0H9Pz_LPnP"
      },
      "id": "vV0H9Pz_LPnP"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(WordPiece(), )\n",
        "tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[PAD]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n",
        "\n",
        "tokenizer_ru = Tokenizer(WordPiece(), )\n",
        "tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[PAD]\", \"[START]\", \"[END]\", ])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"
      ],
      "metadata": {
        "id": "FFWB1J7YKV9l"
      },
      "id": "FFWB1J7YKV9l",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.decoder = decoders.WordPiece()\n",
        "tokenizer_ru.decoder = decoders.WordPiece()"
      ],
      "metadata": {
        "id": "7dvjTwZoKY0L"
      },
      "id": "7dvjTwZoKY0L",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c готовым декодером\n",
        "# вызываем токенайзер, чтобы превратить всё в индексы\n",
        "# потом делаем из индексов обратно текст\n",
        "tokenizer_ru.decoder.decode(tokenizer_ru.encode('Пример текста с редким словом').tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oFrxteNKr66",
        "outputId": "d5f4d9ff-88c0-45bb-855c-84c742d1ad22"
      },
      "id": "3oFrxteNKr66",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'пример текста с редким словом'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# раскоментируйте эту ячейку при обучении токенизатора\n",
        "# а потом снова закоментируйте чтобы при перезапуске не перезаписать токенизаторы\n",
        "# tokenizer_en.save('tokenizer_en')\n",
        "# tokenizer_ru.save('tokenizer_ru')"
      ],
      "metadata": {
        "id": "X4vd1YTULCYS"
      },
      "id": "X4vd1YTULCYS",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ],
      "metadata": {
        "id": "pIyraxYxLECS"
      },
      "id": "pIyraxYxLECS",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Переводим текст в индексы"
      ],
      "metadata": {
        "id": "FgxHw-SSLVb7"
      },
      "id": "FgxHw-SSLVb7"
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, tokenizer, target=False):\n",
        "    if target:\n",
        "        return [tokenizer.token_to_id('[START]')] + tokenizer.encode(text).ids + \\\n",
        "                [tokenizer.token_to_id('[END]')]\n",
        "    else:\n",
        "        return tokenizer.encode(text).ids\n"
      ],
      "metadata": {
        "id": "660KmJG_LUvd"
      },
      "id": "660KmJG_LUvd",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7fc2dae1"
      },
      "outputs": [],
      "source": [
        "# Кодируем и паддим\n",
        "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, True) for t in ru_sents]"
      ],
      "id": "7fc2dae1"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "281b5b90"
      },
      "outputs": [],
      "source": [
        "# выбор максимальной длины\n",
        "max_len_en = np.max([len(x) for x in X_en])\n",
        "max_len_ru = np.max([len(x) for x in X_ru])"
      ],
      "id": "281b5b90"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5984886a",
        "outputId": "0251bfea-754d-4a7d-9c55-dba527842f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17863, 19389)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "max_len_en, max_len_ru"
      ],
      "id": "5984886a"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Исходный язык')\n",
        "print('50 % текстов <= ', np.percentile([len(x) for x in X_en], 50))\n",
        "print('75 % текстов <= ', np.percentile([len(x) for x in X_en], 75))\n",
        "print('90 % текстов <= ', np.percentile([len(x) for x in X_en], 90))\n",
        "print('95 % текстов <= ', np.percentile([len(x) for x in X_en], 95))\n",
        "print('99 % текстов <= ', np.percentile([len(x) for x in X_en], 99))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRANnT0bL471",
        "outputId": "10664d70-df48-4c8d-f372-cb7311d6c270"
      },
      "id": "iRANnT0bL471",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный язык\n",
            "50 % текстов <=  10.0\n",
            "75 % текстов <=  18.0\n",
            "90 % текстов <=  33.0\n",
            "95 % текстов <=  45.0\n",
            "99 % текстов <=  75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Целевой язык')\n",
        "print('50 % текстов <= ', np.percentile([len(x) for x in X_ru], 50))\n",
        "print('75 % текстов <= ', np.percentile([len(x) for x in X_ru], 75))\n",
        "print('90 % текстов <= ', np.percentile([len(x) for x in X_ru], 90))\n",
        "print('95 % текстов <= ', np.percentile([len(x) for x in X_ru], 95))\n",
        "print('99 % текстов <= ', np.percentile([len(x) for x in X_ru], 99))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl0_LiT-L6dM",
        "outputId": "cd26d784-ed6c-49c1-afc2-9c37e37940cd"
      },
      "id": "Tl0_LiT-L6dM",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Целевой язык\n",
            "50 % текстов <=  11.0\n",
            "75 % текстов <=  20.0\n",
            "90 % текстов <=  36.0\n",
            "95 % текстов <=  48.0\n",
            "99 % текстов <=  79.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в seq2seq длины могут быть разными\n",
        "max_len_en, max_len_ru = 45, 48"
      ],
      "metadata": {
        "id": "l2DAccxHL9cq"
      },
      "id": "l2DAccxHL9cq",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вытащим тэг паддинга из словаря и будет использовать его\n",
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeX4x3nmMFAD",
        "outputId": "1c541c54-fd73-426c-ed45-e4140020598f"
      },
      "id": "CeX4x3nmMFAD",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Три матрицы"
      ],
      "metadata": {
        "id": "DqUwhce5NnAQ"
      },
      "id": "DqUwhce5NnAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# На вход модели мы будем подавать три матрицы.\n",
        "\n",
        "X_en = keras.preprocessing.sequence.pad_sequences(\n",
        "              X_en, maxlen=max_len_en, padding='post', value=PAD_IDX)\n",
        "\n",
        "X_ru_out = keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post',\n",
        "              value=PAD_IDX)\n",
        "\n",
        "X_ru_dec = keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1,\n",
        "              padding='post', value=PAD_IDX)"
      ],
      "metadata": {
        "id": "5uJCL-0hMK_O"
      },
      "id": "5uJCL-0hMK_O",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U0QXLgkaM3Ug",
        "outputId": "91f14f7c-f8f7-4932-cac3-794e839c7a2b"
      },
      "id": "U0QXLgkaM3Ug",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"yeah, that's not exactly...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Первая - X_en - это индексы токенов в английских текстах (тут все как и в предыдущих семинарах)\n",
        "X_en[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okKpmXuOM7Cu",
        "outputId": "303f4ee5-a04f-4af7-bdbd-af2e104eada4"
      },
      "id": "okKpmXuOM7Cu",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3280,   13, 2763,    8,   58, 2808, 5148, 2856,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# А вот русскоязычные тексты мы будем подавать через две матрицы\n",
        "# - одна будет использоваться как вход для декодера (X_ru_dec),\n",
        "# а вторая как правильные ответы (X_ru_out)."
      ],
      "metadata": {
        "id": "YN5pDFPGNVww"
      },
      "id": "YN5pDFPGNVww",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "d751b1d5",
        "outputId": "25d20e7a-224a-46f1-bed9-d859c0ff3b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'да, но не совсем...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "ru_sents[0]"
      ],
      "id": "d751b1d5"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ed95081e",
        "outputId": "08284a19-72b1-4e10-a270-68dc379afc59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 2588,   15, 2589, 2513, 5362, 2643,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_ru_dec[0]"
      ],
      "id": "ed95081e"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "14d7c918",
        "outputId": "4a873d18-e7a5-4481-9830-1e01f2e89b04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2588,   15, 2589, 2513, 5362, 2643,    3,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_ru_out[0]"
      ],
      "id": "14d7c918"
    },
    {
      "cell_type": "code",
      "source": [
        "# миллион примеров\n",
        "X_en.shape, X_ru_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-74g5CUNkFg",
        "outputId": "4ddd8974-61d5-48fa-fb8f-8f329638f417"
      },
      "id": "q-74g5CUNkFg",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000000, 45), (1000000, 47))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разделяем на трейн и тест"
      ],
      "metadata": {
        "id": "vQaj97G7N5DB"
      },
      "id": "vQaj97G7N5DB"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "25fa5f05"
      },
      "outputs": [],
      "source": [
        "(X_en_train, X_en_valid,\n",
        "X_ru_dec_train, X_ru_dec_valid,\n",
        "X_ru_out_train, X_ru_out_valid) = train_test_split(X_en,\n",
        "                                                  X_ru_dec,\n",
        "                                                  X_ru_out,\n",
        "                                                  test_size=0.05)"
      ],
      "id": "25fa5f05"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9faa719"
      },
      "source": [
        "Дальше код модели, он взят вот отсюда (с небольшими изменениями) - https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "id": "d9faa719"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Имплементация трансформера"
      ],
      "metadata": {
        "id": "PSsq8PyFOUKH"
      },
      "id": "PSsq8PyFOUKH"
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    # Считаем скалярное произведение между запросом (query) и ключом (key), транспонируя ключ\n",
        "    matmul_qk = keras.ops.matmul(query, keras.ops.transpose(key, axes=[0, 1, 3, 2]))\n",
        "\n",
        "    # Получаем глубину (размерность) ключа и преобразуем ее во float\n",
        "    depth = keras.ops.cast(key.shape[-1], torch.float32)\n",
        "\n",
        "    # Делим результат скалярного произведения на квадратный корень из глубины\n",
        "    # Это делается для уменьшения влияния больших значений и стабилизации градиентов во время обучения\n",
        "    logits = matmul_qk / keras.ops.sqrt(depth)\n",
        "\n",
        "    # Если есть маска, применяем ее к логитам, чтобы обнулить нежелательные значения\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # Применяем функцию softmax для получения весов внимания\n",
        "    attention_weights = keras.ops.softmax(logits, axis=-1)\n",
        "\n",
        "    # Умножаем веса внимания на значения (value) для получения итогового результата\n",
        "    output = keras.ops.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "3SuhMFwlOV2X"
      },
      "id": "3SuhMFwlOV2X",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads  # количество голов для внимания\n",
        "        self.d_model = d_model  # размерность вектора модели\n",
        "\n",
        "        # Убеждаемся, что размерность модели делится нацело на количество голов\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads  # размерность каждой головы\n",
        "\n",
        "        # Создаем полносвязные слои для запроса, ключа и значения\n",
        "        self.query_dense = keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = keras.layers.Dense(units=d_model)\n",
        "\n",
        "        # Создаем последний полносвязный слой\n",
        "        self.dense = keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        # Разделяем входные данные на головы\n",
        "        inputs = keras.ops.reshape(\n",
        "            inputs, newshape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return keras.ops.transpose(inputs, axes=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs.get('mask', None)\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Пропускаем запрос, ключ и значение через соответствующие полносвязные слои\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # Разделяем запрос, ключ и значение на головы\n",
        "        # то есть просто разрезаем вектора на num_heads частей\n",
        "        # и сравниваем все части между собой\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # Выполняем механизм внимания с масштабированным скалярным произведением\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = keras.ops.transpose(scaled_attention, axes=[0, 2, 1, 3])\n",
        "\n",
        "        # Объединяем головы вместе (склеиваем векторы в один)\n",
        "        concat_attention = keras.ops.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # Пропускаем объединенное внимание через дополнительный полносвязный слой\n",
        "        # Он просто добавляет сложности нашей модели\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "GlOWcHY3cX68"
      },
      "id": "GlOWcHY3cX68",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Маски"
      ],
      "metadata": {
        "id": "TKQoOby7h5GA"
      },
      "id": "TKQoOby7h5GA"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5c48cea2"
      },
      "outputs": [],
      "source": [
        "# токен – pad или не pad\n",
        "def create_padding_mask(x):\n",
        "    mask = keras.ops.cast(keras.ops.equal(x, PAD_IDX), torch.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, None, None, :]"
      ],
      "id": "5c48cea2"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "64790293",
        "outputId": "b57cb305-047e-4394-b727-7e67e97a5b19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 0., 0.]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "create_padding_mask([[1,2,3]]) # 1 подставилась для индекса который равен PAD_IDX"
      ],
      "id": "64790293"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "21c0c899"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    # эта функция немножко сложная, но суть у нее достаточно простая\n",
        "    # нужно создать треугольную маску, с помощью которой мы закроем\n",
        "    # для каждого токена все последующие токены\n",
        "    seq_len = x.shape[1]\n",
        "    ones_mask = keras.ops.ones((1, seq_len, seq_len), dtype=\"int32\")\n",
        "    row_index = keras.ops.cumsum(ones_mask, axis=-2)\n",
        "    col_index = keras.ops.cumsum(ones_mask, axis=-1)\n",
        "    look_ahead_mask = ~ keras.ops.greater_equal(row_index, col_index)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return keras.ops.maximum(look_ahead_mask, padding_mask)"
      ],
      "id": "21c0c899"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "b6f988e6",
        "outputId": "d8b84907-4a73-4b7a-a180-f00dfc5550fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[False,  True,  True],\n",
              "         [False, False,  True],\n",
              "         [False, False, False]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# для декодера нам нужно замаскировать следующие токены\n",
        "# так как мы пытаемся их сгенерировать\n",
        "# для этого создается вот такая маска\n",
        "ones_mask = keras.ops.ones((1, 3, 3), dtype=\"int32\")\n",
        "row_index = keras.ops.cumsum(ones_mask, axis=-2)\n",
        "col_index = keras.ops.cumsum(ones_mask, axis=-1)\n",
        "mask = ~ keras.ops.greater_equal(row_index, col_index)\n",
        "mask"
      ],
      "id": "b6f988e6"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "499d2f3d",
        "outputId": "4aa72910-d9e5-4790-f69f-793b82435487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[   0, -100, -100],\n",
              "         [   0,    0, -100],\n",
              "         [   0,    0,    0]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# в слое с вниманием эта маска будет использоваться чтобы занулить близости с токенами из будущего\n",
        "(mask * -100)"
      ],
      "id": "499d2f3d"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9c0f62e3",
        "outputId": "9967b763-9eed-4d90-bea5-9c4d94b72e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1.],\n",
              "          [1., 0., 1.],\n",
              "          [1., 0., 0.]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# эта функция также проверяет и паддинг и если он есть то и его тоже замаскирует\n",
        "# 1 - это паддинг айди\n",
        "create_look_ahead_mask(torch.LongTensor([[1,3,2]]))"
      ],
      "id": "9c0f62e3"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7a1f209e",
        "outputId": "ea7cd304-15c0-40f6-a27f-bdf3df2cbebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 1., 1.],\n",
              "          [0., 0., 1.],\n",
              "          [0., 0., 0.]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "create_look_ahead_mask(torch.Tensor([[2,4,3]]))"
      ],
      "id": "7a1f209e"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "41493f7e",
        "outputId": "6024c271-fcde-4562-ed69-6430583677cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 1., 1.],\n",
              "          [0., 0., 1.],\n",
              "          [0., 0., 0.]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "create_look_ahead_mask(torch.Tensor([[2,4,3]]))"
      ],
      "id": "41493f7e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Позиционное кодирование"
      ],
      "metadata": {
        "id": "-HgAGMm7j78c"
      },
      "id": "-HgAGMm7j78c"
    },
    {
      "cell_type": "code",
      "source": [
        "# в трансформер передается информация о порядке слов\n",
        "# Класс PositionalEncoding генерирует вектор для каждой позиции заданной размерности.\n",
        "# Размерность задается также через d_model, чтобы можно было просто прибавить к вектору слова\n",
        "\n",
        "class PositionalEncoding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / keras.ops.power(10000, (2 * (i // 2)) / d_model)\n",
        "        return keras.ops.multiply(position, angles)\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=torch.arange(0, position, dtype=torch.float32)[:, None],\n",
        "            i=torch.arange(0, d_model, dtype=torch.float32)[None, :],\n",
        "            d_model=d_model)\n",
        "        sines = keras.ops.sin(angle_rads[:, 0::2])\n",
        "        cosines = keras.ops.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = keras.ops.concatenate([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[None, ...]\n",
        "        return keras.ops.cast(pos_encoding, torch.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :inputs.shape[1], :]"
      ],
      "metadata": {
        "id": "BAd6Lkw9j9Cw"
      },
      "id": "BAd6Lkw9j9Cw",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "NgT0_CFvkf1I"
      },
      "id": "NgT0_CFvkf1I"
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    #call_mha\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention = keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    outputs = keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "tpMzZAAAkrrA"
      },
      "id": "tpMzZAAAkrrA",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name=\"encoder\"):\n",
        "    inputs = keras.Input(shape=(max_len,), name=\"inputs\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= keras.ops.sqrt(keras.ops.cast(d_model, torch.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    #inputs (они тут называются outputs но это просто такой нейминг,\n",
        "    # этот параметр передается в encoder_layer первым и encoder_layer будет считать его inputs)\n",
        "    # outputs он тут называется для удобства, так как он будет перезаписываться\n",
        "    # чтобы на вход следующему блоку подавать уже не эмбединги,\n",
        "    # а то что получится как результат предыдущего блока\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "635GXM1Pk5ub"
      },
      "id": "635GXM1Pk5ub",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "e5aytm3GnUgq"
      },
      "id": "e5aytm3GnUgq"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "a2f90e7c"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "    attention1 = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention2 = keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    outputs = keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "a2f90e7c"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1c0dd6a2"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name='decoder'):\n",
        "    inputs = keras.Input(shape=(max_len,), name='inputs')\n",
        "    enc_outputs = keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= keras.ops.sqrt(keras.ops.cast(d_model, torch.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "1c0dd6a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbd2160e"
      },
      "source": [
        "### Модель целиком\n",
        "\n",
        "Общая модель состоит из энкодера, декодера и еще 1 полносвязного слоя. Дополнительный последний слой нужен, чтобы из векторов получить вероятности классов (=слов)"
      ],
      "id": "fbd2160e"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "e356741b"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                max_len,\n",
        "                name=\"transformer\"):\n",
        "    inputs = keras.Input(shape=(max_len[0],), name=\"inputs\")\n",
        "    dec_inputs = keras.Input(shape=(max_len[1]-1,), name=\"dec_inputs\")\n",
        "\n",
        "    enc_padding_mask = keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "    look_ahead_mask = keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    dec_padding_mask = keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    enc_outputs = encoder(\n",
        "                          vocab_size=vocab_size[0],\n",
        "                          num_layers=num_layers,\n",
        "                          units=units,\n",
        "                          d_model=d_model,\n",
        "                          num_heads=num_heads,\n",
        "                          dropout=dropout,\n",
        "                          max_len=max_len[0],\n",
        "                        )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    dec_outputs = decoder(\n",
        "                          vocab_size=vocab_size[1],\n",
        "                          num_layers=num_layers,\n",
        "                          units=units,\n",
        "                          d_model=d_model,\n",
        "                          num_heads=num_heads,\n",
        "                          dropout=dropout,\n",
        "                          max_len=max_len[1]-1,\n",
        "                        )(inputs=[dec_inputs, enc_outputs,\n",
        "                                  look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    outputs = keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "id": "e356741b"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d23ece2d"
      },
      "outputs": [],
      "source": [
        "# на вход подаются не вероятности, а логиты, то есть просто результат полносвязного слоя без активации\n",
        "L  = keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none',)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    loss = L(y_true, y_pred)\n",
        "\n",
        "    mask = keras.ops.cast(keras.ops.not_equal(y_true, PAD_IDX), torch.float32)\n",
        "    loss = keras.ops.multiply(loss, mask)\n",
        "\n",
        "    return keras.ops.mean(loss)"
      ],
      "id": "d23ece2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4743513"
      },
      "source": [
        "Определяем параметры модели. Есть стандартные наборы параметров для обучения маленькой, средней или большой модели. Их можно посмотреть в оригинальной статье про трансформер - https://arxiv.org/pdf/1706.03762.pdf\n",
        "\n",
        "Мы возьмем маленький, т.к. он требует меньше ресурсов. НО для практической задачи есть смысл использовать модель побольше, есть статьи в которые показано, что большие трансформеры требуют даже меньше данных для обучения -  https://arxiv.org/pdf/2002.11794.pdf."
      ],
      "id": "a4743513"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "542fcc43"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "# small model\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "\n",
        "# average model\n",
        "# NUM_LAYERS = 6\n",
        "# D_MODEL = 512\n",
        "# NUM_HEADS = 8\n",
        "# UNITS = 2048\n",
        "# DROPOUT = 0.1\n",
        "\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    max_len=[max_len_en, max_len_ru])\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(\n",
        "    0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('model_ruen.weights.h5',\n",
        "                                            monitor='val_loss',\n",
        "                                            verbose=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True,\n",
        "                                            mode='min',\n",
        "                                            save_freq='epoch')"
      ],
      "id": "542fcc43"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6590325"
      },
      "source": [
        "Размер батча здесь уже имеет большое значение: сликом маленький батч приведет к сильному увеличению времени на обучение, но сильно большим его поставить не получится, т.к. модель большая и быстро займет всю видеокарту."
      ],
      "id": "c6590325"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "439f7e12",
        "outputId": "8b7d4616-39a0-4306-c2f8-a4b1b3ae8876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "id": "439f7e12"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1b2673cd"
      },
      "outputs": [],
      "source": [
        "# model.load_weights('model_ruen.weights.h5')"
      ],
      "id": "1b2673cd"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308a8e81",
        "outputId": "2ad2d826-49f5-45e8-d8a0-f3adeec858fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.0887 - loss: 1.6192\n",
            "Epoch 1: val_loss improved from inf to 0.98794, saving model to model_ruen.weights.h5\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1704s\u001b[0m 359ms/step - accuracy: 0.0887 - loss: 1.6191 - val_accuracy: 0.1461 - val_loss: 0.9879\n",
            "Epoch 2/3\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.1472 - loss: 0.9732\n",
            "Epoch 2: val_loss improved from 0.98794 to 0.88990, saving model to model_ruen.weights.h5\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 360ms/step - accuracy: 0.1472 - loss: 0.9732 - val_accuracy: 0.1580 - val_loss: 0.8899\n",
            "Epoch 3/3\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.1585 - loss: 0.8749\n",
            "Epoch 3: val_loss improved from 0.88990 to 0.85133, saving model to model_ruen.weights.h5\n",
            "\u001b[1m4750/4750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 360ms/step - accuracy: 0.1585 - loss: 0.8749 - val_accuracy: 0.1630 - val_loss: 0.8513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6d51313430>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train,\n",
        "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
        "             batch_size=200,\n",
        "             epochs=3,\n",
        "             callbacks=[checkpoint]\n",
        "             )"
      ],
      "id": "308a8e81"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d61cb6ed"
      },
      "source": [
        "###Оценка качества модели вручную"
      ],
      "id": "d61cb6ed"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "63762869"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def translate(text):\n",
        "    input_ids = encode(text, tokenizer_en, target=False)\n",
        "\n",
        "    input_ids = keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [input_ids], maxlen=max_len_en, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32)\n",
        "\n",
        "\n",
        "\n",
        "    output_ids = [tokenizer_ru.token_to_id('[START]') ]\n",
        "\n",
        "    pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "\n",
        "    while pred.argmax(2)[0][-1] not in [tokenizer_ru.token_to_id('[END]')]:\n",
        "        if len(output_ids) >= max_len_ru:\n",
        "            break\n",
        "        # можно занизить скор тэга UNK чтобы он никогда не генерировался\n",
        "        pred[:, :, tokenizer_ru.token_to_id('[UNK]')] = -100\n",
        "\n",
        "        output_ids.append(pred.argmax(2)[0][-1])\n",
        "        pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "                                      [output_ids], maxlen=max_len_ru-1, padding='post',\n",
        "                                       # важно не забыть паддинг с нужным id\n",
        "                                       value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    return tokenizer_ru.decode(output_ids[1:], )\n"
      ],
      "id": "63762869"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5f16e8b5",
        "outputId": "3e8f6682-c1f9-4810-9fc8-a3813ff44706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'трансформатортортортертеререртеререртеререр'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "translate(\"Transformer\")"
      ],
      "id": "5f16e8b5"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7d0ee1b8",
        "outputId": "85c45913-3154-4c0d-cb53-88bf7f788a04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'вы можете перевести это?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "translate(\"can you translate this sentence?\")"
      ],
      "id": "7d0ee1b8"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aa0b57d2",
        "outputId": "d083d5af-3137-46c6-db6c-67de70a7c362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'пожалуйста перевод на,, пожалуйста,,,,,,, пожалуйста,,,,,,,,,,,,, пожалуйста,,,,,,,,, пожалуйста,,,,.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "translate(\"please translate this sentence into russian\")"
      ],
      "id": "aa0b57d2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU"
      ],
      "metadata": {
        "id": "I-OD953Mwn90"
      },
      "id": "I-OD953Mwn90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX9WvnhW_UNV"
      },
      "source": [
        "Реализация bleu есть в nltk"
      ],
      "id": "MX9WvnhW_UNV"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "2735e9d0"
      },
      "outputs": [],
      "source": [
        "# %pip install nltk"
      ],
      "id": "2735e9d0"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YbuJQX9S8E0o"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ],
      "id": "YbuJQX9S8E0o"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1e75c215"
      },
      "outputs": [],
      "source": [
        "text = open('opus.en-ru-test.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-test.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()"
      ],
      "id": "1e75c215"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TbLvCxxlFCn6"
      },
      "outputs": [],
      "source": [
        "en_sents_test = open('opus.en-ru-test.en').read().lower().splitlines()\n",
        "ru_sents_test = open('opus.en-ru-test.ru').read().lower().splitlines()"
      ],
      "id": "TbLvCxxlFCn6"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuj_lcoUFg9W",
        "outputId": "6da5ca31-fceb-49ed-c874-3ae19cbcf9c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['if you only stay there.',\n",
              " \"i don't know how you do it, pop, carrying these boxes around every day.\",\n",
              " 'we might have a slight edge in mediation.',\n",
              " 'how long is it going to take you to get him what he needs?',\n",
              " \"on 1 april president of the nagorno karabagh republic bako sahakyan met head of the general staff of the republic of armenia's armed forces colonel-general yuri khachaturov.\",\n",
              " 'mr priesner also noted that the e-justice management system has not only improved case management, but has also led to a significant streamlining in procedures.',\n",
              " \"you don't like chicken noodle soup?\",\n",
              " 'posted: 14 may 2005, 20:31',\n",
              " 'now, for a minute, i thought maybe he was being tailed.',\n",
              " '« : 26 октябрь 2017, 06:50:24 »']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "en_sents_test[:10]"
      ],
      "id": "Cuj_lcoUFg9W"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRY7yBESGYxa",
        "outputId": "ed278da8-ceb4-4658-bbce-fc91f38c3c63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['только бы не вылететь.',\n",
              " 'и как ты только справляешься, папа, таская эти коробки взад-вперед целый день.',\n",
              " 'возможно, у нас есть небольшое преимущество в переговорах.',\n",
              " 'сколько времени вы будете делать то, что ему нужно?',\n",
              " '1 апреля президент нкр бако саакян принял начальника генштаба вооруженных сил республики армения генерал-полковника юрия хачатурова.',\n",
              " 'г-н приснер также упомянул, что система электронного правосудия не только позволила улучшить процесс ведения дел, но также способствует значительному упорядочению процедур.',\n",
              " '- неплохо, да.',\n",
              " 'posted: 15 dec 2006, 00:07',\n",
              " 'и на минутку я подумал, что за ним могут следить.',\n",
              " '«: 11 октябрь 2011, 17:15:34»']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "ru_sents_test[:10]"
      ],
      "id": "pRY7yBESGYxa"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Dy0cRSoLFC0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1eda846-eaa9-4021-c25c-1438cb0d5226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ 20 переводов:\n",
            "BLEU score: 1.0\n",
            "Английское предложение: 12844\n",
            "Правильный перевод: 12844\n",
            "Наш перевод: 12844\n",
            "\n",
            "BLEU score: 1.0\n",
            "Английское предложение: s5000\n",
            "Правильный перевод: s5000\n",
            "Наш перевод: s5000\n",
            "\n",
            "BLEU score: 1.0\n",
            "Английское предложение: published: 24 october 2014\n",
            "Правильный перевод: опубликовано: 24 октябрь 2014\n",
            "Наш перевод: опубликовано : 24 октябрь 2014\n",
            "\n",
            "BLEU score: 1.0\n",
            "Английское предложение: spain ( 15 apartments) apartments\n",
            "Правильный перевод: испания ( 15 апартаментов) апартаментов\n",
            "Наш перевод: испания ( 15 апартаментов ) апартаментов\n",
            "\n",
            "BLEU score: 1.0\n",
            "Английское предложение: jon: what is this?\n",
            "Правильный перевод: что это?\n",
            "Наш перевод: что это?\n",
            "\n",
            "BLEU score: 1.0\n",
            "Английское предложение: 6624\n",
            "Правильный перевод: 6624\n",
            "Наш перевод: 6624\n",
            "\n",
            "BLEU score: 0.668740304976422\n",
            "Английское предложение: sound: [k]\n",
            "Правильный перевод: звук: [k]\n",
            "Наш перевод: звуко : [ k ]\n",
            "\n",
            "BLEU score: 0.6115380576901023\n",
            "Английское предложение: cincinnati (ohio) 513231 **** mobile\n",
            "Правильный перевод: цинциннати (огайо) 513231 **** мобильный\n",
            "Наш перевод: цинцинциннана ( огайо ) 513231 **** мобильный\n",
            "\n",
            "BLEU score: 0.6065306597126334\n",
            "Английское предложение: тема: fibra óptica\n",
            "Правильный перевод: тема: -\n",
            "Наш перевод: тема :\n",
            "\n",
            "BLEU score: 0.6065306597126334\n",
            "Английское предложение: александр , 32\n",
            "Правильный перевод: дмитрий , 32\n",
            "Наш перевод: дмитрий,\n",
            "\n",
            "BLEU score: 0.6065306597126334\n",
            "Английское предложение: 320757\n",
            "Правильный перевод: 320757\n",
            "Наш перевод: 32075\n",
            "\n",
            "BLEU score: 0.5814307369682193\n",
            "Английское предложение: i'm not saying, because that's too personal.\n",
            "Правильный перевод: я не говорю потому, что это слишком личное.\n",
            "Наш перевод: я не говорю потому, что слишком личное..?\n",
            "\n",
            "BLEU score: 0.5789300674674098\n",
            "Английское предложение: you don't know janeway.\n",
            "Правильный перевод: ты не знаешь джейнвей.\n",
            "Наш перевод: ты не знаешь джейн.\n",
            "\n",
            "BLEU score: 0.5783569866465142\n",
            "Английское предложение: read about hostel van gogh in your own language\n",
            "Правильный перевод: читайте о hostel van gogh в вашем родном языке\n",
            "Наш перевод: читайте о hostel v vgh в вашем родном языке языке языке\n",
            "\n",
            "BLEU score: 0.5779390907776394\n",
            "Английское предложение: fax: +39.0431.439415\n",
            "Правильный перевод: факс: +39.0431.430671\n",
            "Наш перевод: fax : + 39. 0431.\n",
            "\n",
            "BLEU score: 0.5475182535069453\n",
            "Английское предложение: resolution 1321 (2000)\n",
            "Правильный перевод: резолюция 1321 (2000),\n",
            "Наш перевод: резолюция 1321 ( )\n",
            "\n",
            "BLEU score: 0.5444460596606694\n",
            "Английское предложение: \"nice work, henry?\"\n",
            "Правильный перевод: \"хорошая работа, генри.?\"\n",
            "Наш перевод: \" хорошая работа, генри?\"\n",
            "\n",
            "BLEU score: 0.5205510363053438\n",
            "Английское предложение: sat, 03/15/2014 - 22:03\n",
            "Правильный перевод: сб, 03/15/2014 - 22:03\n",
            "Наш перевод: sat, 03 / 15 / 2014 - - - 22 02 :\n",
            "\n",
            "BLEU score: 0.5078431769269642\n",
            "Английское предложение: lottery numbers: 2 , 11 , 12 , 19 , 26 , 41\n",
            "Правильный перевод: лотерея номера: 2, 11, 12, 19, 26, 41\n",
            "Наш перевод: лотерея номера :, 11 12, 19, 26,,,\n",
            "\n",
            "BLEU score: 0.4482700320176827\n",
            "Английское предложение: beam (m):3.5\n",
            "Правильный перевод: ширина (м):2.2\n",
            "Наш перевод: ширина ( м ): 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# предсказание переводов для всех предложений в тестовой выборке\n",
        "translations = [translate(en_sent) for en_sent in en_sents_test]\n",
        "\n",
        "# рассчитываем BLEU для каждого предложения\n",
        "bleu_scores = []\n",
        "for i, translation in enumerate(translations):\n",
        "    reference = tokenizer_ru.encode(ru_sents_test[i]).tokens\n",
        "    hypothesis = tokenizer_ru.encode(translation).tokens\n",
        "    bleu_score = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, auto_reweigh=True)\n",
        "    bleu_scores.append((i, bleu_score))\n",
        "\n",
        "# сортируем предложения по BLEU\n",
        "sorted_bleu_scores = sorted(bleu_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# функция для вывода лучших переводов согласно BLEU\n",
        "def print_top_translations(sorted_bleu_scores, translations, n=20):\n",
        "    print(\"Топ\", n, \"переводов:\")\n",
        "    for i in range(n):\n",
        "        index, bleu_score = sorted_bleu_scores[i]\n",
        "        print(\"BLEU score:\", bleu_score)\n",
        "        print(\"Английское предложение:\", en_sents_test[index])\n",
        "        print(\"Правильный перевод:\", ru_sents_test[index])\n",
        "        print(\"Наш перевод:\", translations[index])\n",
        "        print()\n",
        "\n",
        "print_top_translations(sorted_bleu_scores, translations)"
      ],
      "id": "Dy0cRSoLFC0k"
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_scores_values = [score for _, score in bleu_scores]\n",
        "\n",
        "average_bleu_score = (sum(bleu_scores_values) / len(bleu_scores_values)) * 100\n",
        "print(\"Средний BLEU-скор:\", average_bleu_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccATDZUnWTek",
        "outputId": "6dcc8a52-f364-46f6-f585-7fa15517a1c3"
      },
      "id": "ccATDZUnWTek",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средний BLEU-скор: 2.0443447847407654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwuh1mO8Icw0"
      },
      "source": [
        "BLEU обычно показывают не от 0 до 1, а от 0 до 100."
      ],
      "id": "Lwuh1mO8Icw0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оптимизация функции translate"
      ],
      "metadata": {
        "id": "saXMGREMX3Zj"
      },
      "id": "saXMGREMX3Zj"
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def translate_batch(texts, batch_size=3):\n",
        "    translations = []\n",
        "    nb_samples = len(texts)\n",
        "    for idx in range(0, nb_samples, batch_size):\n",
        "        batch_texts = texts[idx:idx+batch_size]\n",
        "        batch_translations = translate_parallel(batch_texts)\n",
        "        translations.extend(batch_translations)\n",
        "    return translations\n",
        "\n",
        "def translate_parallel(batch_texts):\n",
        "    input_ids = [encode(text, tokenizer_en, target=False) for text in batch_texts]\n",
        "    input_ids = keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "        input_ids, maxlen=max_len_en, padding='post',\n",
        "        value=PAD_IDX), torch.int32)\n",
        "\n",
        "    output_ids = [[tokenizer_ru.token_to_id('[START]')]] * len(batch_texts)\n",
        "    pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "        output_ids, maxlen=max_len_ru-1, padding='post',\n",
        "        value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    while not all(pred.argmax(2)[:, -1] == tokenizer_ru.token_to_id('[END]')):\n",
        "        if len(output_ids[0]) >= max_len_ru:\n",
        "            break\n",
        "        pred[:, :, tokenizer_ru.token_to_id('[UNK]')] = -100\n",
        "        next_words = pred.argmax(2)[:, -1]\n",
        "        output_ids = [output + [word] if word != tokenizer_ru.token_to_id('[END]') else output for output, word in zip(output_ids, next_words)]\n",
        "        pred = model((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "            output_ids, maxlen=max_len_ru-1, padding='post',\n",
        "            value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    return [tokenizer_ru.decode(output[1:]) for output in output_ids]\n"
      ],
      "metadata": {
        "id": "rtwF0JRMjnhj"
      },
      "id": "rtwF0JRMjnhj",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"If you only stay there.\",\n",
        "    \"We might have a slight edge in mediation.\",\n",
        "    \"I don't know how you do it, pop, carrying these boxes around every day.\",\n",
        "    \"please translate this sentence into russian\",\n",
        "    \"can you translate this sentence?\",\n",
        "    \"And finally the last sentence\"\n",
        "]\n",
        "\n",
        "# размер батча\n",
        "batch_size = 7\n",
        "\n",
        "translations = translate_batch(texts, batch_size)\n",
        "\n",
        "for text, translation in zip(texts, translations):\n",
        "    print(\"Оригинал:\", text)\n",
        "    print(\"Перевод:\", translation)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u2IB3-yjrB3",
        "outputId": "abb5b321-d5d8-4583-cd74-b1ac78cc4e4f"
      },
      "id": "-u2IB3-yjrB3",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оригинал: This is the first sentence.\n",
            "Перевод: это первое предложение.\n",
            "\n",
            "Оригинал: If you only stay there.\n",
            "Перевод: если ты останешься там.. если ты там? не?.. если ты не?.\n",
            "\n",
            "Оригинал: We might have a slight edge in mediation.\n",
            "Перевод: у нас нас собеседование по делам посредни. может?. нам может. может........... нам может. может..........\n",
            "\n",
            "Оригинал: I don't know how you do it, pop, carrying these boxes around every day.\n",
            "Перевод: я не знаю,, ли ты ты,, попи,и,ррииииииииии.!!!!!!! я не знаю,,,.....\n",
            "\n",
            "Оригинал: please translate this sentence into russian\n",
            "Перевод: пожалуйста перевод на,, пожалуйста,,,,,,, пожалуйста,,,,,,,,,,,,, пожалуйста,,,,,,,,, пожалуйста,,,,.\n",
            "\n",
            "Оригинал: can you translate this sentence?\n",
            "Перевод: вы можете перевести это?\n",
            "\n",
            "Оригинал: And finally the last sentence\n",
            "Перевод: и последнее предложение\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.parallel\n",
        "from torch.nn.parallel import DataParallel\n",
        "\n",
        "@torch.no_grad()\n",
        "def translate_batch(texts, batch_size=3):\n",
        "    translations = []\n",
        "    nb_samples = len(texts)\n",
        "    for idx in range(0, nb_samples, batch_size):\n",
        "        batch_texts = texts[idx:idx+batch_size]\n",
        "        batch_translations = translate_parallel(batch_texts)\n",
        "        translations.extend(batch_translations)\n",
        "    return translations\n",
        "\n",
        "def translate_parallel(batch_texts):\n",
        "    device_ids = [0, 1]\n",
        "\n",
        "    # обертка модели в DataParallel\n",
        "    model_parallel = DataParallel(model, device_ids=device_ids)\n",
        "\n",
        "    input_ids = [encode(text, tokenizer_en, target=False) for text in batch_texts]\n",
        "    input_ids = keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "        input_ids, maxlen=max_len_en, padding='post',\n",
        "        value=PAD_IDX), torch.int32)\n",
        "\n",
        "    output_ids = [[tokenizer_ru.token_to_id('[START]')]] * len(batch_texts)\n",
        "    pred = model_parallel((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "        output_ids, maxlen=max_len_ru-1, padding='post',\n",
        "        value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    while not all(pred.argmax(2)[:, -1] == tokenizer_ru.token_to_id('[END]')):\n",
        "        if len(output_ids[0]) >= max_len_ru:\n",
        "            break\n",
        "        pred[:, :, tokenizer_ru.token_to_id('[UNK]')] = -100\n",
        "        next_words = pred.argmax(2)[:, -1]\n",
        "        output_ids = [output + [word] if word != tokenizer_ru.token_to_id('[END]') else output for output, word in zip(output_ids, next_words)]\n",
        "        pred = model_parallel((input_ids, keras.ops.cast(keras.preprocessing.sequence.pad_sequences(\n",
        "            output_ids, maxlen=max_len_ru-1, padding='post',\n",
        "            value=PAD_IDX), torch.int32))).cpu().numpy()\n",
        "\n",
        "    return [tokenizer_ru.decode(output[1:]) for output in output_ids]\n"
      ],
      "metadata": {
        "id": "5hWSzZyKnU8y"
      },
      "id": "5hWSzZyKnU8y",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b5aa93d6",
      "metadata": {
        "id": "b5aa93d6"
      },
      "source": [
        "\n",
        "## Задание 2 (2 балла).\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
        "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
        "\n",
        "Ответ должен содержать как минимум 10 предложений.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Техника Backtranslation применяется для улучшения качества машинного перевода, особенно в ситуациях, когда у нас недостаточно обучающих данных. Это разновидность аугментации данных, при которой берутся тексты того языка, на который мы хотим переводить, и переводятся на тот язык, с которого мы переводим. Полученные синтетические параллельные корпуса добавляются к исходным обучающим данным. Модель после этого генерирует переводы качественнее, потому что в аугментированных данных показано, как должны выглядеть правильные переводы на целевой язык.\n",
        "\n",
        "Как применить к задаче en->ru перевода:\n",
        "1. Обучить модель переводить с русского на английский на исходном параллельном корпусе.\n",
        "2. Найти большой корпус с русскими текстами, используя нашу модель перевести их на английский. Так мы получим новый синтетический параллельный корпус, где английские тексты будут не очень хорошими, зато русские, целевые, очень хорошими.\n",
        "3. Объединить синтетический корпус с исходным.\n",
        "4. Обучить модель переводить с английского на русский на новом увеличенном корпусе.  \n",
        "\n",
        "Итого, понадобится две модели, каждую надо будет обучить по одному разу."
      ],
      "metadata": {
        "id": "Jr4budwuqMHU"
      },
      "id": "Jr4budwuqMHU"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}