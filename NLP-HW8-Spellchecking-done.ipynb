{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e5fa87-1e8f-4ea5-81e5-2ec2954ddfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in /Users/dariachelnokova/myenv/lib/python3.11/site-packages (4.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa6f734-8958-4fa3-90c1-900d132a97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0111778-cf43-4bfb-b544-057a7ff846e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# библиотека для отслеживания прогресса\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78aa9b6-0bec-4e7c-99b9-0540d3b9cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пояним эту мысль.\n",
      "Поясним эту мысль\n"
     ]
    }
   ],
   "source": [
    "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "# Посмотрим на пары предложений\n",
    "print(bad[2])\n",
    "print(true[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a975ce4-e62a-4cdc-ae42-64e0e5a0165a",
   "metadata": {},
   "source": [
    "### Без ранжирования равнозначных по расстоянию редактирования кандидатов по вероятности (с семинара)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32ae032-9e1d-4acf-b2a1-2ba3b232d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
    "# разобьем предложение по пробелам и удалим пунктуация на границах слов\n",
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d927ff69-2bcf-43a2-9b42-0a853efd8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('апофеозом', 'опофеозом'),\n",
      " ('дня', 'дня'),\n",
      " ('для', 'для'),\n",
      " ('меня', 'меня'),\n",
      " ('сегодня', 'сегодня'),\n",
      " ('стала', 'стала'),\n",
      " ('фраза', 'фраза'),\n",
      " ('услышанная', 'услышанная'),\n",
      " ('в', 'в'),\n",
      " ('новостях', 'новостях')]\n"
     ]
    }
   ],
   "source": [
    "pprint(align_words(true[1], bad[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6627cd8-fd7d-4341-96fb-a51f68a1661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = []\n",
    "total = 0\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    \n",
    "    \n",
    "    for pair in word_pairs:\n",
    "        if pair[0] != pair[1]:\n",
    "            mistakes.append(pair)\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a559aa9-178c-4ccd-b2c8-85acda10e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля ошибок -  0.12886443221610805\n"
     ]
    }
   ],
   "source": [
    "print('Доля ошибок - ', len(mistakes)/total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d3638c-af2e-4a74-bbdd-af78eeefff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('сегодня', 'седня'), 24),\n",
       " (('вообще', 'вобще'), 18),\n",
       " (('вообще', 'ваще'), 17),\n",
       " (('естественно', 'естесственно'), 17),\n",
       " (('хочется', 'хочеться'), 16),\n",
       " (('кстати', 'кстате'), 16),\n",
       " (('очень', 'ооочень'), 14),\n",
       " (('как-то', 'както'), 9),\n",
       " (('очень', 'оооочень'), 9),\n",
       " (('это', 'ето'), 9)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mistakes).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9596adf-952a-4ca6-86ec-a572ee05bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('data/wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad15a8a-5d8d-4ab9-ae03-8e059974414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 267296),\n",
       " ('и', 147115),\n",
       " ('на', 81926),\n",
       " ('с', 61681),\n",
       " ('года', 43894),\n",
       " ('по', 37235),\n",
       " ('году', 32197),\n",
       " ('из', 29150),\n",
       " ('был', 23293),\n",
       " ('не', 23228)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0172f7ed-5aaa-459f-942b-cedbdc4a2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск ближайшего слова по косинусному расстоянию\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    \n",
    "    # вся эффективноть берется из того, что мы сразу считаем близость \n",
    "    # 1 вектора ко всей матрице (словам в словаре)\n",
    "    # считать по отдельности циклом было бы дольше\n",
    "    # вместо одного вектора может даже целая матрица\n",
    "    # тогда считаться в итоге будет ещё быстрее\n",
    "    \n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c70fc25-89e5-4612-ba7c-a19fa42935d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 99.4 ms, total: 302 ms\n",
      "Wall time: 536 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('цоссен', 0.05131670194948623),\n",
       " ('цоссене', 0.05612019255146106),\n",
       " ('концессионное', 0.08649972160886044),\n",
       " ('солнце', 0.0871290708247231),\n",
       " ('сценок', 0.0871290708247231),\n",
       " ('сценой', 0.0871290708247231),\n",
       " ('сосновец', 0.09630388588493599),\n",
       " ('сено', 0.10557280900008414),\n",
       " ('носе', 0.10557280900008414),\n",
       " ('броненосец', 0.10557280900008414),\n",
       " ('сенокосцев', 0.10557280900008414),\n",
       " ('соне', 0.10557280900008414),\n",
       " ('бессоннице', 0.10557280900008414),\n",
       " ('сное', 0.10557280900008414),\n",
       " ('бесценного', 0.10557280900008414),\n",
       " ('сцен', 0.10557280900008414),\n",
       " ('броненосце', 0.10557280900008414),\n",
       " ('онсе', 0.10557280900008414),\n",
       " ('лентоносец', 0.10557280900008414),\n",
       " ('осен', 0.10557280900008414)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_vec('сонце', X, vec) # это расстояние - чем меньше тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7688331-959f-40de-b072-a4ccf68b628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск наиболее похожего слова по расстоянию Левенштейна\n",
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    # Counter можно использовать и с не целыми числами\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795a8137-3db2-4f7d-91fb-b7a83ddd792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 313 ms, total: 24.9 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334),\n",
       " ('конце', 0.8),\n",
       " ('монце', 0.8),\n",
       " ('соне', 0.8),\n",
       " ('сонче', 0.8),\n",
       " ('донце', 0.8),\n",
       " ('солнцем', 0.7142857142857143),\n",
       " ('солнцев', 0.7142857142857143),\n",
       " ('солнца', 0.6666666666666667),\n",
       " ('сочное', 0.6666666666666667),\n",
       " ('синице', 0.6666666666666667),\n",
       " ('солнцу', 0.6666666666666667),\n",
       " ('сочные', 0.6666666666666667),\n",
       " ('свинце', 0.6666666666666667),\n",
       " ('сфорце', 0.6666666666666667),\n",
       " ('монцей', 0.6666666666666667),\n",
       " ('ньонце', 0.6666666666666667),\n",
       " ('соньер', 0.6666666666666667),\n",
       " ('сорное', 0.6666666666666667),\n",
       " ('донцем', 0.6666666666666667)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('сонце', word2id, topn=20, metric=textdistance.levenshtein) # это расстояние - чем меньше тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "874b7175-590d-463a-9c0a-b31a3b644d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гибридный поиск наиболее похожего слова\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093bc010-f735-4dfd-8d4a-05bbf57a6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 177 ms, sys: 19.8 ms, total: 197 ms\n",
      "Wall time: 222 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334),\n",
       " ('соне', 0.8),\n",
       " ('сное', 0.6),\n",
       " ('онсе', 0.6),\n",
       " ('сосновец', 0.5)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_hybrid_match('сонце', X, vec, topn=5, metric=textdistance.damerau_levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd48e4d-a4d2-4971-a024-333b366aa56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# общее количество слов в словаре\n",
    "N = sum(vocab.values())\n",
    "\n",
    "\n",
    "# вероятность слова на основе его относительной частоты в словаре\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "# возвращаем 1, если слово отсутствует в словаре vocab (то есть считается ошибкой) и 0, если слово присутствует в словаре.\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cdba33b-fda1-47e7-bfa3-6d5de5dffd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb84c624089410ea865dbcf4e68e538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847023511755878\n",
      "0.421583850931677\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "# оценка качества функции get_closest_hybrid_match (без ранжирования равнозначных по расстоянию редактирования кандидатов по вероятности)\n",
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n",
    "\n",
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d972009-d0ad-4f1a-b1e1-9e2f5cc8894e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ea8599-fc41-4890-ae00-f88b0d32cd8f",
   "metadata": {},
   "source": [
    "### Выбор наиболее вероятного слова из кандидатов с одинаковым расстоянием редактирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef6b2b43-31ff-4b71-81a4-b152e9f5032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match_ranked(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein, vocab=vocab):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn * 4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    # Создаем список для хранения кандидатов с одинаковым расстоянием редактирования\n",
    "    candidates_with_equal_distance = []\n",
    "\n",
    "    # Ищем n первых кандидатов с одинаковым расстоянием редактирования\n",
    "    for n in range(1, len(closest) + 1):\n",
    "        equal_distance = len(set(dist for _, dist in closest[:n])) == 1\n",
    "        if equal_distance:\n",
    "            # Сохраняем их по очереди в список, пока не найдем отличие в расстоянии\n",
    "            candidates_with_equal_distance.append(closest[n - 1])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if candidates_with_equal_distance:  # Если есть кандидаты с одинаковым расстоянием\n",
    "        # Добавляем их вероятности\n",
    "        candidates_with_equal_distance = [(word, dist, P(word)) for word, dist in candidates_with_equal_distance]\n",
    "        # Ранжируем список по вероятности\n",
    "        candidates_with_equal_distance.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        # Получаем оставшихся кандидатов\n",
    "        remaining_candidates = closest[len(candidates_with_equal_distance):]\n",
    "\n",
    "        # Объединяем первых ранжированных по вероятностям кандидатов с остальными\n",
    "        merged_candidates = candidates_with_equal_distance + remaining_candidates\n",
    "\n",
    "        return merged_candidates\n",
    "    else:\n",
    "        return closest  # Возвращаем исходный список, если не нашли кандидатов с одинаковым расстоянием\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09e43ef9-e627-4b45-b7fb-77f712204cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 ms, sys: 142 ms, total: 346 ms\n",
      "Wall time: 750 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('приват', 0.8333333333333334),\n",
       " ('привет', 0.8333333333333334),\n",
       " ('привить', 0.7142857142857143),\n",
       " ('привито', 0.7142857142857143),\n",
       " ('правит', 0.6666666666666667)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_hybrid_match('привт', X, vec, topn=5, metric=textdistance.damerau_levenshtein)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea53cc8e-74fe-4fc7-af36-5938ff06cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('приват', 0.8333333333333334, 3.685543243254777e-06),\n",
       " ('привет', 0.8333333333333334, 2.7156634423982565e-06),\n",
       " ('привить', 0.7142857142857143),\n",
       " ('привито', 0.7142857142857143),\n",
       " ('правит', 0.6666666666666667)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"приват\" и \"привет\" – одинаковое расстояние редактирования, при этом \"приват\" – первый кандидат, тк встречается чаще в словаре\n",
    "get_closest_hybrid_match_ranked('привт', X, vec, topn=5, metric=textdistance.damerau_levenshtein, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db46a670-160f-4788-b465-f90af5ac7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 213 ms, sys: 82.1 ms, total: 295 ms\n",
      "Wall time: 421 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334),\n",
       " ('солнцу', 0.8333333333333334),\n",
       " ('солнца', 0.8333333333333334),\n",
       " ('солонцы', 0.7142857142857143),\n",
       " ('солнцем', 0.7142857142857143)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_hybrid_match('солнц', X, vec, topn=5, metric=textdistance.damerau_levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8605ddfe-fab9-4bd6-8770-91af91bd8bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.220000938843647e-05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(\"солнца\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33192a3-e06b-45b6-8e43-87a4f061c0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.444097098158431e-05"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(\"солнце\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a602c45b-aa4b-4d5b-b15f-62689b6f3bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(\"солнца\") > P(\"солнце\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa3dccb8-2fc8-4fe7-bec9-faf915114849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('солнца', 0.8333333333333334, 3.220000938843647e-05),\n",
       " ('солнце', 0.8333333333333334, 2.444097098158431e-05),\n",
       " ('солнцу', 0.8333333333333334, 3.103615362740865e-06),\n",
       " ('солонцы', 0.7142857142857143)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"солнца\" вероятнее, чем \"солнце\"\n",
    "get_closest_hybrid_match_ranked('солнц', X, vec, topn=4, metric=textdistance.damerau_levenshtein, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218f7de-74e6-4ca3-bf8a-69cc5258be00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54554c93-1142-45db-b035-94d7e461c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8503a8a31a4f0eba7e19900cda80a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848224112056028\n",
      "0.4309006211180124\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "# оценка качества функции get_closest_hybrid_match_ranked (с ранжированием по вероятности)\n",
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1], get_closest_hybrid_match_ranked(pair[1], X, vec)[0][0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n",
    "\n",
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be78d8f3-25de-434c-b0a0-3daee818fa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов\n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!) \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e89c4-9404-41a0-ac3a-b639e07c0539",
   "metadata": {},
   "source": [
    "#### 1)  Составляется словарь правильных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cf0dfac-7776-4c24-b0ed-2b2e6e0d54a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пояним эту мысль.\n",
      "Поясним эту мысль\n"
     ]
    }
   ],
   "source": [
    "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "# Посмотрим на пары предложений\n",
    "print(bad[2])\n",
    "print(true[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32438668-8a53-4cd8-bc5c-9f7dc30f68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
    "# разобьем предложение по пробелам и удалим пунктуация на границах слов\n",
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d89e56fc-a8d9-4d2c-a24e-8781076be300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368801\n"
     ]
    }
   ],
   "source": [
    "corpus = open('data/wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall(r'\\w+', corpus.lower()))\n",
    "\n",
    "print(len(vocab)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b54f17-bb69-444c-a6ad-4b8fc755fab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "851ff475-c8cc-4fcd-a232-fe313405b4a6",
   "metadata": {},
   "source": [
    "#### 2)  Создание словаря удалений: Для каждого слова из словаря правильных слов создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "879e64a2-1449-47ff-8308-40ce266046f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2872451\n"
     ]
    }
   ],
   "source": [
    "def edits1(word):\n",
    "    letters = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    return deletes\n",
    "\n",
    "# Создаем словарь удалений на основе словаря правильных слов\n",
    "delete_dict = {}\n",
    "for word in vocab:\n",
    "    deletions = edits1(word)\n",
    "    for deletion in deletions:\n",
    "        if deletion not in delete_dict:\n",
    "            delete_dict[deletion] = word\n",
    "\n",
    "print(len(delete_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e683a65a-e661-404d-a364-94939665330d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['оыостройка',\n",
       " 'ныостройка',\n",
       " 'ноостройка',\n",
       " 'ноыстройка',\n",
       " 'ноыотройка',\n",
       " 'ноыосройка',\n",
       " 'ноыостойка',\n",
       " 'ноыострйка',\n",
       " 'ноыострока',\n",
       " 'ноыостройа',\n",
       " 'ноыостройк']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits1(\"ноыостройка\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e94b5e7-0d1a-4555-992c-0b5e1f1a1fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('овостройка', 'новостройка')\n",
      "('нвостройка', 'новостройка')\n",
      "('ноостройка', 'новостройка')\n",
      "('новстройка', 'новостройка')\n",
      "('новотройка', 'новостройка')\n",
      "('новосройка', 'новостройка')\n",
      "('новостойка', 'новостройка')\n",
      "('новострйка', 'новостройка')\n",
      "('новострока', 'новостройка')\n",
      "('новостройа', 'новостройка')\n",
      "('новостройк', 'новостройка')\n",
      "('ижегородская', 'нижегородская')\n",
      "('нжегородская', 'нижегородская')\n",
      "('ниегородская', 'нижегородская')\n",
      "('нижгородская', 'нижегородская')\n",
      "('нижеородская', 'нижегородская')\n",
      "('нижегродская', 'нижегородская')\n",
      "('нижегоодская', 'нижегородская')\n",
      "('нижегордская', 'нижегородская')\n",
      "('нижегороская', 'нижегородская')\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "for key in islice(delete_dict.items(), 20):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f0c54-29f3-4b0f-b028-28c356ae014f",
   "metadata": {},
   "source": [
    "#### 3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "#### 4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c2f1e68-6695-4518-9fc1-ce6e2ffbad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_with_probability(word, delete_dict, vocab):\n",
    "    # Генерируем варианты удалений для слова с опечаткой\n",
    "    word_deletes = edits1(word)\n",
    "    \n",
    "    # Создаем пустой список для потенциальных исправлений\n",
    "    possible_corrections = []\n",
    "    \n",
    "    # Итерируемся по вариантам удалений слова с опечаткой\n",
    "    for delete in word_deletes:\n",
    "        # проверяем, есть ли данный вариант удаления в словаре удалений\n",
    "        if delete in delete_dict:\n",
    "            # Если есть, добавляем соответствующее правильное слово в список потенциальных исправлений\n",
    "            possible_corrections.append(delete_dict[delete])\n",
    "    \n",
    "    # Если есть потенциальные исправления\n",
    "    if possible_corrections:\n",
    "        # Выбираем наиболее вероятное правильное слово на основе его вероятности в словаре\n",
    "        corrected_word = max(possible_corrections, key=lambda x: P(x, N=N))\n",
    "        return corrected_word  # Возвращаем наиболее вероятное исправление\n",
    "    \n",
    "    # Если нет потенциальных исправлений, возвращаем исходное слово\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53d72d31-d75a-4e23-aefc-d91b69b50331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 281 µs, total: 345 µs\n",
      "Wall time: 360 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'новостройка'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('иовостройка', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e1bf79a-ec6a-4aa3-a0da-c1a266fe6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77 µs, sys: 242 µs, total: 319 µs\n",
      "Wall time: 331 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'солнце'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('солнке', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1d3bdaa-f8d8-401f-85ce-37c1de397d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 111 µs, total: 145 µs\n",
      "Wall time: 150 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'козырь'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('козырт', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "566a8c54-a16b-4eb2-987d-cc8a4769a187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 µs, sys: 204 µs, total: 254 µs\n",
      "Wall time: 259 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'конце'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('сонце', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78db688b-d109-4eff-8bb7-bd3176c3e2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865200a97ed245688a482889dd2f96a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        # чтобы два раза не исправлять одно и тоже слово - закешируем его\n",
    "        # перед тем как считать исправление проверим нет ли его в кеше\n",
    "        \n",
    "        predicted = cashed.get(pair[1], correct_spelling_with_probability(pair[1], delete_dict, vocab))\n",
    "        cashed[pair[1]] = predicted\n",
    "        \n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "454f94aa-5f90-4002-b79e-5554d5ca6402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511255627813907\n",
      "0.20263975155279504\n",
      "0.4430917652463535\n"
     ]
    }
   ],
   "source": [
    "print(correct/total) # процент правильных \n",
    "print(mistaken_fixed/total_mistaken) # сколько мы правильно ошибок исправили (только половину)\n",
    "print(correct_broken/total_correct) # сколько раз исправляем правильные слова на неправильные"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
